<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>（项目）20251113大数据项目实施2——springboot编写脚本后台 | zhangzhang-blog</title><meta name="keywords" content="RAG,fastgpt,Docker,LLM,AI,springboot"><meta name="author" content="zhangzhang"><meta name="copyright" content="zhangzhang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="（项目）20251113大数据项目实施2——springboot编写脚本后台"><meta name="application-name" content="（项目）20251113大数据项目实施2——springboot编写脚本后台"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="（项目）20251113大数据项目实施2——springboot编写脚本后台"><meta property="og:url" content="http://example.com/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD2%E2%80%94%E2%80%94springboot%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%20(2)/index.html"><meta property="og:site_name" content="zhangzhang-blog"><meta property="og:description" content="二、封装模型重训练 + 重部署接口，实现状态监控并对接前端与 FastGPT具体要做的事：  编写脚本，封装模型重训练 + 重部署接口，支持从业务系统数据库获取数据用于重训练，训练完成后自动完成模型重部署； 实现重训练 + 重部署的状态监控功能，实时跟踪流程进度（如数据获取中、训练中、部署中、完成"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=d012df38-e625-0bf5-dc5f-b86079e11f31"><meta property="article:author" content="zhangzhang"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=d012df38-e625-0bf5-dc5f-b86079e11f31"><meta name="description" content="二、封装模型重训练 + 重部署接口，实现状态监控并对接前端与 FastGPT具体要做的事：  编写脚本，封装模型重训练 + 重部署接口，支持从业务系统数据库获取数据用于重训练，训练完成后自动完成模型重部署； 实现重训练 + 重部署的状态监控功能，实时跟踪流程进度（如数据获取中、训练中、部署中、完成"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD2%E2%80%94%E2%80%94springboot%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%20(2)/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: {"enable":true,"img":"https://upload-bbs.miyoushe.com/upload/2024/07/27/125766904/ba62475f396df9de3316a08ed9e65d86_5680958632268053399..png"},
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":null},
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: zhangzhang","link":"链接: ","source":"来源: zhangzhang-blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'zhangzhang-blog',
  title: '（项目）20251113大数据项目实施2——springboot编写脚本后台',
  postAI: '',
  pageFillDescription: '二、封装模型重训练 + 重部署接口实现状态监控并对接前端与 FastGPT, 现有三段功能不同的代码：, 1.Trade_Transformer_LSTM_price.py, 2.Trade_Transformer_LSTM_quantity.py, 3.app.py/Trade_FlaskApp_Transformer.py, 代码功能逻辑, 1. 文件 1：进/出口贸易「数量」预测训练脚本, 2. 文件 2：进/出口贸易「单价」预测训练脚本, 3. 文件 3：Flask API 部署脚本, 三者关系与整体流程, 核心总结, 基于springboot框架生成后端接口, 项目完成情况, 项目结构, 已创建的核心文件, 核心功能, API 接口, 配置说明, 使用步骤二封装模型重训练重部署接口实现状态监控并对接前端与具体要做的事编写脚本封装模型重训练重部署接口支持从业务系统数据库获取数据用于重训练训练完成后自动完成模型重部署实现重训练重部署的状态监控功能实时跟踪流程进度如数据获取中训练中部署中完成失败提供两个对接前端的接口一个用于触发重训练重部署的命令接口另一个用于向前端推送供前端获取状态的通知接口确保重部署完成后工作流调用的四个预测进口价格进口数量出口价格出口数量能使用最新训练的模型进行预测现有三段功能不同的代码加载和预处理数据进口出口提取年月列数据年月数据年月特征列调整贸易伙伴编码商品编码贸易方式编码注册地编码计量单位数量人民币包含连续变量已包含年月单价原始目标变量名清理数据在清洗完数据之后标准化之前添加先确保非负单价单价单价标准化变换后的目标变量清理连续变量中的异常值删除含有的行包括类别连续和目标变量对类别变量做强制转字符串防止报错归一化连续变量包括和按商品分组创建时间序列商品编码历史窗口长度确保有足够数据点创建序列转换为数组没有足够数据创建序列请检查数据或减小分割训练集和测试集不打乱转换为张量创建增大小批量验证早停机制类方案一使用可学习的位置编码混合模型时间维度平均初始化模型训练获取每个类别特征的唯一值数量方案二混合模型给金额较低权重表示耐心程度当连续多少个时停止训练开始训练防止梯度爆炸验证保存模型评估最佳模型开始验证合并所有批次的结果反标准化计算指标评估数量评估单价打印部分样本部分预测值真实值预测单价真实单价绘图部分绘制预测真实曲线真实单价预测单价单价预测值真实值样本索引单价绘制误差分布直方图预测误差分布误差真实值预测值频数绘制曲线训练过程中记录的训练损失曲线保存和模型和预处理器已成功保存同步播放程序会暂停直到播放结束训练完成加载和预处理数据进口出口提取年月列数据年月数据年月特征列调整贸易伙伴编码商品编码贸易方式编码注册地编码计量单位数量人民币包含连续变量已包含年月数量原始目标变量名清理数据在清洗完数据之后标准化之前添加先确保非负数量数量数量标准化变换后的目标变量清理连续变量中的异常值删除含有的行包括类别连续和目标变量对类别变量做强制转字符串防止报错归一化连续变量包括和按商品分组创建时间序列商品编码历史窗口长度确保有足够数据点创建序列转换为数组没有足够数据创建序列请检查数据或减小分割训练集和测试集不打乱转换为张量创建增大小批量验证早停机制类方案一使用可学习的位置编码混合模型时间维度平均初始化模型训练获取每个类别特征的唯一值数量输入维度大小隐藏层大小注意力头数层的数量表示耐心程度当连续多少个时停止训练开始训练防止梯度爆炸验证保存模型评估最佳模型开始验证合并所有批次的结果反标准化计算指标评估数量评估数量打印部分样本部分预测值真实值预测数量真实数量绘图部分绘制预测真实曲线真实数量预测数量数量预测值真实值样本索引数量绘制误差分布直方图预测误差分布误差真实值预测值频数绘制曲线训练过程中记录的训练损失曲线保存和模型和预处理器已成功保存同步播放程序会暂停直到播放结束训练完成加载模型参数进口单价数量出口单价数量定义类别特征列和连续特征列必须与训练时一致贸易伙伴编码商品编码贸易方式编码注册地编码计量单位数量人民币时间序列长度必须与训练时一致加载和定义模型结构必须与训练时一致时间维度平均实例化模型并加载权重输入维度大小隐藏层大小注意力头数层的数量输入维度大小隐藏层大小注意力头数层的数量数据库连接配置开发环境生产环境贸易伙伴名称商品名称贸易方式注册地名称构建目标日期无效的年月查询语句贸易伙伴名称商品名称贸易方式名称注册地名称数据年月数据年月贸易伙伴名称商品名称贸易方式名称注册地名称数据年月数据年月连接数据库并执行查询转换为历史数据不足条预测结果准确度受影响复制数据补齐到条先提取数据年月字段并做预处理数据年月缺少数据年月字段确保数据年月列是字符串类型数据年月数据年月如果数据是格式但含数据年月数据年月转换为无法解析的设为数据年月数据年月检查是否有无效日期数据年月存在无法解析的日期请检查以下记录提取数据年月数据年月检查类别特征列是否存在缺失以下类别特征列类别特征编码连续特征标准化保存处理后的结果构造输入模型预测反变换如果用了人民币计量单位转换为历史数据不足条预测结果准确度受影响复制数据补齐到条先提取数据年月字段并做预处理数据年月缺少数据年月字段确保数据年月列是字符串类型数据年月数据年月如果数据是格式但含数据年月数据年月转换为无法解析的设为数据年月数据年月检查是否有无效日期数据年月存在无法解析的日期请检查以下记录提取数据年月数据年月检查类别特征列是否存在缺失以下类别特征列类别特征编码连续特征标准化保存处理后的结果构造输入模型预测反变换如果用了计量单位转换为历史数据不足条预测结果准确度受影响复制数据补齐到条先提取数据年月字段并做预处理数据年月缺少数据年月字段确保数据年月列是字符串类型数据年月数据年月如果数据是格式但含数据年月数据年月转换为无法解析的设为数据年月数据年月检查是否有无效日期数据年月存在无法解析的日期请检查以下记录提取数据年月数据年月检查类别特征列是否存在缺失以下类别特征列类别特征编码连续特征标准化保存处理后的结果构造输入模型预测反变换如果用了人民币计量单位转换为历史数据不足条预测结果准确度受影响复制数据补齐到条先提取数据年月字段并做预处理数据年月缺少数据年月字段确保数据年月列是字符串类型数据年月数据年月如果数据是格式但含数据年月数据年月转换为无法解析的设为数据年月数据年月检查是否有无效日期数据年月存在无法解析的日期请检查以下记录提取数据年月数据年月检查类别特征列是否存在缺失以下类别特征列类别特征编码连续特征标准化保存处理后的结果构造输入模型预测反变换如果用了计量单位代码功能逻辑文件进出口贸易数量预测训练脚本核心作用基于出口贸易数据训练混合模型用于预测未来月份的贸易数量关键流程数据处理加载出口数据提取年月特征清理缺失值异常值类别特征编码连续特征归一化对数变换目标变量数量序列构建按商品编码分组生成个月为窗口的时间序列数据输入历史个月特征输出第个月数量模型训练定义混合模型含可学习位置编码使用损失优化器训练早停机制防止过拟合保存模型权重预处理组件评估可视化计算指标绘制预测真实曲线误差分布训练损失曲线文件进出口贸易单价预测训练脚本核心作用基于进口贸易数据训练混合模型用于预测未来月份的贸易单价关键流程与文件的差异数据差异加载进口数据目标变量改为单价数据保存路径指向进口模型目录模型参数调整更复杂模型适配单价预测损失权重设为降低高金额样本的影响输出产物保存进口单价预测模型对应的预处理组件评估指标和可视化图表针对单价文件部署脚本核心作用将前两个文件训练好的个模型进口单价数量出口单价数量封装为接口通过数据库查询历史数据提供实时预测服务关键流程模型加载加载个预训练模型权重对应的和初始化模型结构与训练时一致数据库交互提供函数根据请求参数贸易伙伴商品时间等查询进口出口历史数据最近条接口设计个接口接收请求预测流程数据预处理与训练时一致编码类别特征归一化连续特征处理数据不足条的情况复制补齐模型推理反变换预测结果还原对数变换和标准化返回结果预测值单位警告信息三者关系与整体流程文件出口数量训练输出出口数量模型预处理组件文件部署文件进口单价训练输出进口单价模型预处理组件接收请求查询数据库预处理模型推理前端其他系统调用预测接口输出出口数量模型预处理组件输出进口单价模型预处理组件接收请求查询数据库预处理模型推理文件出口数量训练文件部署文件进口单价训练前端其他系统调用预测接口核心总结文件核心目标输入数据输出产物文件训练出口数量预测模型出口贸易出口数量模型可视化图表文件训练进口单价预测模型进口贸易进口单价模型可视化图表文件提供预测服务请求数据库数据格式预测结果单价数量基于框架生成后端接口其实是基于描述要你基于框架开发两个接口主接口接收前端调用按顺序执行三个脚本先进出口数量训练再进出口单价训练最后部署需支持通过代码配置进出口的数据路径替代手动注释切换和模型生成路径确保自动读取进出口输出进出口模型组件自动读取进出口输出进出口模型组件且的输出能被正确引用状态接口向前端返回脚本执行状态运行中完成失败等核心优化修改文件进出口训练和文件进出口训练的代码通过参数或配置实现进出口导入路径模型输出路径的自动切换分别指定无需手动注释切换路径将完整项目代码放入新的文件目录中项目完成情况项目结构主启动类脚本配置类控制器脚本执行服务训练任务管理服务脚本执行结果模型训练任务状态模型脚本状态枚举配置文件单价训练脚本数量训练脚本部署脚本需从原项目复制配置文件项目说明文档已创建的核心文件主应用主启动类配置文件配置管理配置属性类支持从读取配置控制器提供训练任务启动和状态查询接口服务层脚本执行服务训练任务管理服务数据模型脚本执行结果模型训练任务状态模型状态枚举脚本单价训练脚本已参数化数量训练脚本已参数化文档项目说明文档快速启动指南项目结构说明核心功能自动化训练流程按顺序执行个模型的训练进口数量进口单价出口数量出口单价参数化配置通过配置路径和模型输出路径无需修改代码状态跟踪实时跟踪训练任务执行状态支持查询进度异步执行训练任务异步执行不阻塞主线程接口启动训练任务查询指定任务状态查询所有任务状态配置说明在中配置解释器路径数据文件路径进口出口模型输出路径进口出口脚本文件路径使用步骤修改中的路径配置运行启动服务调用启动训练通过查询状态所有代码已创建在目录下可直接使用训练脚本已支持通过命令行参数配置无需手动修改代码',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-11-19 22:52:02',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510132339617.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">zhangzhang-blog</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/BFS/" style="font-size: 1.05rem;">BFS<sup>6</sup></a><a href="/tags/Boyer-Moore/" style="font-size: 1.05rem;">Boyer-Moore<sup>1</sup></a><a href="/tags/DFS/" style="font-size: 1.05rem;">DFS<sup>12</sup></a><a href="/tags/DP/" style="font-size: 1.05rem;">DP<sup>11</sup></a><a href="/tags/Hash/" style="font-size: 1.05rem;">Hash<sup>14</sup></a><a href="/tags/Java/" style="font-size: 1.05rem;">Java<sup>62</sup></a><a href="/tags/Kadane-%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">Kadane 算法<sup>1</sup></a><a href="/tags/LeetCode/" style="font-size: 1.05rem;">LeetCode<sup>59</sup></a><a href="/tags/MySQL/" style="font-size: 1.05rem;">MySQL<sup>1</sup></a><a href="/tags/PTA/" style="font-size: 1.05rem;">PTA<sup>93</sup></a><a href="/tags/c/" style="font-size: 1.05rem;">c<sup>29</sup></a><a href="/tags/c/" style="font-size: 1.05rem;">c++<sup>75</sup></a><a href="/tags/git/" style="font-size: 1.05rem;">git<sup>1</sup></a><a href="/tags/vim/" style="font-size: 1.05rem;">vim<sup>1</sup></a><a href="/tags/%E4%B8%89%E6%8C%87%E9%92%88/" style="font-size: 1.05rem;">三指针<sup>5</sup></a><a href="/tags/%E4%B8%B2/" style="font-size: 1.05rem;">串<sup>2</sup></a><a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 1.05rem;">二叉树<sup>6</sup></a><a href="/tags/%E4%BD%9C%E4%B8%9A/" style="font-size: 1.05rem;">作业<sup>73</sup></a><a href="/tags/%E5%85%B1%E4%BA%AB%E6%A0%88/" style="font-size: 1.05rem;">共享栈<sup>1</sup></a><a href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/" style="font-size: 1.05rem;">双指针<sup>20</sup></a><a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 1.05rem;">回溯<sup>6</sup></a><a href="/tags/%E5%9B%BE/" style="font-size: 1.05rem;">图<sup>8</sup></a><a href="/tags/%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/" style="font-size: 1.05rem;">图床搭建<sup>1</sup></a><a href="/tags/%E5%A4%8D%E4%B9%A0/" style="font-size: 1.05rem;">复习<sup>6</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 1.05rem;">工具<sup>9</sup></a><a href="/tags/%E5%BD%92%E5%B9%B6/" style="font-size: 1.05rem;">归并<sup>1</sup></a><a href="/tags/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88/" style="font-size: 1.05rem;">快慢指针<sup>7</sup></a><a href="/tags/%E6%8F%92%E4%BB%B6/" style="font-size: 1.05rem;">插件<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 1.05rem;">数据结构<sup>99</sup></a><a href="/tags/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/" style="font-size: 1.05rem;">栈和队列<sup>25</sup></a><a href="/tags/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 1.05rem;">树和二叉树<sup>18</sup></a><a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 1.05rem;">笔记<sup>4</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">算法<sup>161</sup></a><a href="/tags/%E7%BA%BF%E6%80%A7%E8%A1%A8/" style="font-size: 1.05rem;">线性表<sup>1</sup></a><a href="/tags/%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/" style="font-size: 1.05rem;">缓存问题<sup>1</sup></a><a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 1.05rem;">贪心<sup>2</sup></a><a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 1.05rem;">递归<sup>3</sup></a><a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 1.05rem;">链表<sup>36</sup></a><a href="/tags/%E9%98%BF%E9%87%8C%E4%BA%91/" style="font-size: 1.05rem;">阿里云<sup>1</sup></a><a href="/tags/%E9%A1%BA%E5%BA%8F%E8%A1%A8/" style="font-size: 1.05rem;">顺序表<sup>19</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/12/"><span class="card-archive-list-date">十二月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">39</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/11/"><span class="card-archive-list-date">十一月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">64</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/10/"><span class="card-archive-list-date">十月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">74</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/08/"><span class="card-archive-list-date">八月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/07/"><span class="card-archive-list-date">七月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/05/"><span class="card-archive-list-date">五月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/04/"><span class="card-archive-list-date">四月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%A1%B9%E7%9B%AE/" itemprop="url">项目</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/RAG/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>RAG</span></a><a class="article-meta__tags" href="/tags/fastgpt/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>fastgpt</span></a><a class="article-meta__tags" href="/tags/Docker/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Docker</span></a><a class="article-meta__tags" href="/tags/LLM/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>LLM</span></a><a class="article-meta__tags" href="/tags/AI/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>AI</span></a><a class="article-meta__tags" href="/tags/springboot/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>springboot</span></a></span></div></div><h1 class="post-title" itemprop="name headline">（项目）20251113大数据项目实施2——springboot编写脚本后台</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-11-17T02:19:00.000Z" title="发表于 2025-11-17 10:19:00">2025-11-17</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-11-19T14:52:02.422Z" title="更新于 2025-11-19 22:52:02">2025-11-19</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">9.9k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>48分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="（项目）20251113大数据项目实施2——springboot编写脚本后台"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为武汉"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>武汉</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=d012df38-e625-0bf5-dc5f-b86079e11f31"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD2%E2%80%94%E2%80%94springboot%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%20(2)/"><header><a class="post-meta-categories" href="/categories/%E9%A1%B9%E7%9B%AE/" itemprop="url">项目</a><a href="/tags/RAG/" tabindex="-1" itemprop="url">RAG</a><a href="/tags/fastgpt/" tabindex="-1" itemprop="url">fastgpt</a><a href="/tags/Docker/" tabindex="-1" itemprop="url">Docker</a><a href="/tags/LLM/" tabindex="-1" itemprop="url">LLM</a><a href="/tags/AI/" tabindex="-1" itemprop="url">AI</a><a href="/tags/springboot/" tabindex="-1" itemprop="url">springboot</a><h1 id="CrawlerTitle" itemprop="name headline">（项目）20251113大数据项目实施2——springboot编写脚本后台</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">zhangzhang</span><time itemprop="dateCreated datePublished" datetime="2025-11-17T02:19:00.000Z" title="发表于 2025-11-17 10:19:00">2025-11-17</time><time itemprop="dateCreated datePublished" datetime="2025-11-19T14:52:02.422Z" title="更新于 2025-11-19 22:52:02">2025-11-19</time></header><h1 id="二、封装模型重训练-重部署接口，实现状态监控并对接前端与-FastGPT"><a href="#二、封装模型重训练-重部署接口，实现状态监控并对接前端与-FastGPT" class="headerlink" title="二、封装模型重训练 + 重部署接口，实现状态监控并对接前端与 FastGPT"></a>二、封装模型重训练 + 重部署接口，实现状态监控并对接前端与 FastGPT</h1><p>具体要做的事：</p>
<ul>
<li>编写脚本，封装模型重训练 + 重部署接口，支持从业务系统数据库获取数据用于重训练，训练完成后自动完成模型重部署；</li>
<li>实现重训练 + 重部署的状态监控功能，实时跟踪流程进度（如数据获取中、训练中、部署中、完成 / 失败）；</li>
<li>提供两个对接前端的接口：一个用于触发重训练重部署的命令接口，另一个用于向前端推送 / 供前端获取状态的通知接口；</li>
<li>确保重部署完成后，FastGPT 工作流调用的四个预测 API（进口价格 / 进口数量 / 出口价格 / 出口数量）能使用最新训练的模型进行预测。</li>
</ul>
<h2 id="现有三段功能不同的代码："><a href="#现有三段功能不同的代码：" class="headerlink" title="现有三段功能不同的代码："></a>现有三段功能不同的代码：</h2><h4 id="1-Trade-Transformer-LSTM-price-py"><a href="#1-Trade-Transformer-LSTM-price-py" class="headerlink" title="1.Trade_Transformer_LSTM_price.py"></a>1.Trade_Transformer_LSTM_price.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> winsound</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: 加载和预处理数据</span></span><br><span class="line">file_path = <span class="string">&#x27;F:\Python\Transformer\demo\data\进口\merged_output.csv&#x27;</span></span><br><span class="line"><span class="comment">#file_path = &#x27;F:\Python\Transformer\demo\data\出口\merged_output.csv&#x27;</span></span><br><span class="line">df = pd.read_csv(file_path, encoding=<span class="string">&#x27;UTF-8&#x27;</span>, thousands=<span class="string">&#x27;,&#x27;</span>, low_memory=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取年月列</span></span><br><span class="line">df[<span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>).<span class="built_in">str</span>[:<span class="number">4</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>).<span class="built_in">str</span>[<span class="number">4</span>:].astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征列调整</span></span><br><span class="line">categorical_cols = [<span class="string">&#x27;贸易伙伴编码&#x27;</span>, <span class="string">&#x27;商品编码&#x27;</span>, <span class="string">&#x27;贸易方式编码&#x27;</span>, <span class="string">&#x27;注册地编码&#x27;</span>, <span class="string">&#x27;计量单位&#x27;</span>]</span><br><span class="line">continuous_cols = [<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;数量&#x27;</span>, <span class="string">&#x27;人民币&#x27;</span>]  <span class="comment"># 包含连续变量（已包含年月）</span></span><br><span class="line">target_cols = [<span class="string">&#x27;单价&#x27;</span>]   <span class="comment"># 原始目标变量名</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理数据</span></span><br><span class="line">df[target_cols] = df[target_cols].replace(&#123;<span class="string">&#x27;-&#x27;</span>: np.nan, <span class="string">&#x27;&#x27;</span>: np.nan&#125;, regex=<span class="literal">False</span>)</span><br><span class="line">df[target_cols] = df[target_cols].apply(pd.to_numeric, errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在清洗完数据之后、标准化之前添加：</span></span><br><span class="line">df[target_cols] = df[target_cols].clip(lower=<span class="number">0</span>)  <span class="comment"># 先确保非负</span></span><br><span class="line">df[<span class="string">&#x27;log_单价&#x27;</span>] = np.log1p(df[<span class="string">&#x27;单价&#x27;</span>])</span><br><span class="line">target_cols_log = [<span class="string">&#x27;log_单价&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化 log 变换后的目标变量</span></span><br><span class="line">scaler_y = StandardScaler()</span><br><span class="line">df[target_cols_log] = scaler_y.fit_transform(df[target_cols_log])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理连续变量中的异常值</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> continuous_cols:</span><br><span class="line">    df[col] = df[col].replace(&#123;<span class="string">&#x27;-&#x27;</span>: np.nan, <span class="string">&#x27;&#x27;</span>: np.nan&#125;, regex=<span class="literal">False</span>)</span><br><span class="line">    df[col] = pd.to_numeric(df[col], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除含有 NaN 的行（包括类别、连续和目标变量）</span></span><br><span class="line">df.dropna(subset=categorical_cols + continuous_cols + target_cols_log, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对类别变量做 Label Encoding</span></span><br><span class="line">label_encoders = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols:</span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    df[col] = le.fit_transform(df[col].astype(<span class="built_in">str</span>))  <span class="comment"># 强制转字符串防止报错</span></span><br><span class="line">    label_encoders[col] = le</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化连续变量（包括 year 和 month）</span></span><br><span class="line">scaler_X = StandardScaler()</span><br><span class="line">df[continuous_cols] = scaler_X.fit_transform(df[continuous_cols])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按商品分组创建时间序列</span></span><br><span class="line">grouped = df.groupby(<span class="string">&#x27;商品编码&#x27;</span>)</span><br><span class="line">sequences = []</span><br><span class="line">seq_length = <span class="number">12</span><span class="comment">#历史窗口长度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, group <span class="keyword">in</span> grouped:</span><br><span class="line">    group = group.sort_values([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;month&#x27;</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(group) &lt; seq_length + <span class="number">1</span>:  <span class="comment"># 确保有足够数据点</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建序列</span></span><br><span class="line">    X_cat_group = group[categorical_cols].values</span><br><span class="line">    X_cont_group = group[continuous_cols].values</span><br><span class="line">    y_group = group[target_cols_log].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_cat_group) - seq_length):</span><br><span class="line">        x_cat_seq = X_cat_group[i:i + seq_length]</span><br><span class="line">        x_cont_seq = X_cont_group[i:i + seq_length]</span><br><span class="line">        y_val = y_group[i + seq_length]</span><br><span class="line">        sequences.append((x_cat_seq, x_cont_seq, y_val))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为数组</span></span><br><span class="line"><span class="keyword">if</span> sequences:</span><br><span class="line">    X_cat, X_cont, y = <span class="built_in">zip</span>(*sequences)</span><br><span class="line">    X_cat = np.array(X_cat)</span><br><span class="line">    X_cont = np.array(X_cont)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">&quot;没有足够数据创建序列，请检查数据或减小seq_length&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割训练集和测试集（不打乱）</span></span><br><span class="line">X_cat_train, X_cat_test, X_cont_train, X_cont_test, y_train, y_test = train_test_split(</span><br><span class="line">    X_cat, X_cont, y, test_size=<span class="number">0.2</span>, shuffle=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为PyTorch张量</span></span><br><span class="line">X_cat_train_tensor = torch.tensor(X_cat_train, dtype=torch.long)</span><br><span class="line">X_cont_train_tensor = torch.tensor(X_cont_train, dtype=torch.float32)</span><br><span class="line">y_train_tensor = torch.tensor(y_train, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">X_cat_test_tensor = torch.tensor(X_cat_test, dtype=torch.long)</span><br><span class="line">X_cont_test_tensor = torch.tensor(X_cont_test, dtype=torch.float32)</span><br><span class="line">y_test_tensor = torch.tensor(y_test, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataLoader</span></span><br><span class="line">train_dataset = torch.utils.data.TensorDataset(X_cat_train_tensor, X_cont_train_tensor, y_train_tensor)</span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)  <span class="comment"># 增大batch_size</span></span><br><span class="line">test_dataset = torch.utils.data.TensorDataset(X_cat_test_tensor, X_cont_test_tensor, y_test_tensor)</span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_dataset,</span><br><span class="line">    batch_size=<span class="number">16</span>,   <span class="comment"># 小批量验证</span></span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    num_workers=<span class="number">0</span>,</span><br><span class="line">    pin_memory=<span class="literal">False</span> <span class="keyword">if</span> <span class="keyword">not</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#早停机制类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EarlyStopping</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patience=<span class="number">10</span>, verbose=<span class="literal">False</span>, delta=<span class="number">0</span>, path=<span class="string">&#x27;F:\\Python\\Transformer\\demo\\model\\trade_Transformer_LSTM\\in\\checkpoint_price.pth&#x27;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.patience = patience</span><br><span class="line">        <span class="variable language_">self</span>.verbose = verbose</span><br><span class="line">        <span class="variable language_">self</span>.counter = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.best_score = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.early_stop = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.val_loss_min = np.Inf</span><br><span class="line">        <span class="variable language_">self</span>.delta = delta</span><br><span class="line">        <span class="variable language_">self</span>.path = path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, val_loss, model</span>):</span><br><span class="line">        score = -val_loss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.best_score <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>.best_score = score</span><br><span class="line">            <span class="variable language_">self</span>.save_checkpoint(val_loss, model)</span><br><span class="line">        <span class="keyword">elif</span> score &lt; <span class="variable language_">self</span>.best_score + <span class="variable language_">self</span>.delta:</span><br><span class="line">            <span class="variable language_">self</span>.counter += <span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;EarlyStopping counter: <span class="subst">&#123;self.counter&#125;</span> out of <span class="subst">&#123;self.patience&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.counter &gt;= <span class="variable language_">self</span>.patience:</span><br><span class="line">                <span class="variable language_">self</span>.early_stop = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.best_score = score</span><br><span class="line">            <span class="variable language_">self</span>.save_checkpoint(val_loss, model)</span><br><span class="line">            <span class="variable language_">self</span>.counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_checkpoint</span>(<span class="params">self, val_loss, model</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Validation loss decreased (<span class="subst">&#123;self.val_loss_min:<span class="number">.6</span>f&#125;</span> --&gt; <span class="subst">&#123;val_loss:<span class="number">.6</span>f&#125;</span>). Saving model...&#x27;</span>)</span><br><span class="line">        torch.save(model.state_dict(), <span class="variable language_">self</span>.path)</span><br><span class="line">        <span class="variable language_">self</span>.val_loss_min = val_loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方案一：使用可学习的位置编码</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LearnablePositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.position_embeddings = nn.Embedding(max_len, d_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        positions = torch.arange(<span class="number">0</span>, x.size(<span class="number">1</span>), device=x.device).expand(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = x + <span class="variable language_">self</span>.position_embeddings(positions)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 混合 LSTM + Transformer 模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LSTMTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_embeddings_list, continuous_dim, model_dim=<span class="number">64</span>, hidden_size=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">4</span>, num_layers=<span class="number">2</span>, dropout=<span class="number">0.3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.cat_embeddings = nn.ModuleList([</span><br><span class="line">            nn.Embedding(num_emb, model_dim) <span class="keyword">for</span> num_emb <span class="keyword">in</span> num_embeddings_list</span><br><span class="line">        ])</span><br><span class="line">        <span class="variable language_">self</span>.cont_proj = nn.Linear(continuous_dim, model_dim)</span><br><span class="line">        <span class="variable language_">self</span>.pos_encoder = LearnablePositionalEncoding(model_dim)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.lstm = nn.LSTM(model_dim, hidden_size, batch_first=<span class="literal">True</span>, bidirectional=<span class="literal">False</span>)</span><br><span class="line">        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.norm = nn.LayerNorm(hidden_size)</span><br><span class="line">        <span class="variable language_">self</span>.fc_out = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, cat_inputs, cont_inputs</span>):</span><br><span class="line">        <span class="comment"># Embeddings</span></span><br><span class="line">        embedded_cat = torch.stack([emb(cat_inputs[:, :, i]) <span class="keyword">for</span> i, emb <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.cat_embeddings)], dim=<span class="number">0</span>).<span class="built_in">sum</span>(dim=<span class="number">0</span>)</span><br><span class="line">        embedded_cont = <span class="variable language_">self</span>.cont_proj(cont_inputs)</span><br><span class="line">        x = embedded_cat + embedded_cont</span><br><span class="line">        x = <span class="variable language_">self</span>.pos_encoder(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># LSTM</span></span><br><span class="line">        x, _ = <span class="variable language_">self</span>.lstm(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Transformer</span></span><br><span class="line">        x = x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)  <span class="comment"># [S, B, D]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.transformer(x)</span><br><span class="line">        x = x.mean(dim=<span class="number">0</span>)  <span class="comment"># 时间维度平均</span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc_out(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: 初始化模型 &amp; 训练</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取每个类别特征的唯一值数量</span></span><br><span class="line">num_embeddings_list = [df[col].nunique() <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方案二：混合 LSTM + Transformer 模型</span></span><br><span class="line">model = LSTMTransformer(</span><br><span class="line">    num_embeddings_list=[df[col].nunique() <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols],</span><br><span class="line">    continuous_dim=<span class="built_in">len</span>(continuous_cols),</span><br><span class="line">    model_dim=<span class="number">128</span>,</span><br><span class="line">    hidden_size=<span class="number">128</span>,</span><br><span class="line">    num_heads=<span class="number">64</span>,</span><br><span class="line">    num_layers=<span class="number">10</span>,</span><br><span class="line">    dropout=<span class="number">0.6</span></span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss(<span class="number">0.5</span>)<span class="comment"># 给金额较低权重</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>, weight_decay=<span class="number">1e-5</span>)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, factor=<span class="number">0.5</span>, patience=<span class="number">5</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line">best_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">losses = []</span><br><span class="line">val_losses = []</span><br><span class="line"></span><br><span class="line">early_stopping = EarlyStopping(patience=<span class="number">100</span>, verbose=<span class="literal">True</span>)<span class="comment">#patience表示耐心程度，当连续多少个epoch without improvement时，停止训练</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;开始训练...&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    model.train()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    loop = tqdm(train_loader, desc=<span class="string">f&quot;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x_cat_batch, x_cont_batch, y_batch <span class="keyword">in</span> loop:</span><br><span class="line">        x_cat_batch, x_cont_batch, y_batch = x_cat_batch.to(device), x_cont_batch.to(device), y_batch.to(device)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(x_cat_batch, x_cont_batch)</span><br><span class="line">        loss = criterion(outputs, y_batch)</span><br><span class="line">        loss.backward()</span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)  <span class="comment"># 防止梯度爆炸</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        loop.set_postfix(loss=loss.item())</span><br><span class="line"></span><br><span class="line">    avg_train_loss = total_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">    losses.append(avg_train_loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    val_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> x_cat_val, x_cont_val, y_val <span class="keyword">in</span> test_loader:</span><br><span class="line">            x_cat_val, x_cont_val, y_val = x_cat_val.to(device), x_cont_val.to(device), y_val.to(device)</span><br><span class="line">            val_outputs = model(x_cat_val, x_cont_val)</span><br><span class="line">            loss = criterion(val_outputs, y_val)</span><br><span class="line">            val_loss += loss.item() * x_cat_val.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        val_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    scheduler.step(val_loss)</span><br><span class="line">    val_losses.append(val_loss)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span> | Train Loss: <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span> | Val Loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    logging.basicConfig(filename=<span class="string">&#x27;training_Trade_Transformer_Price.log&#x27;</span>, level=logging.INFO)</span><br><span class="line">    logging.info(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>, Train Loss: <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span>, Val Loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    early_stopping(val_loss, model)</span><br><span class="line">    <span class="keyword">if</span> early_stopping.early_stop:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Early stopping&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  保存模型</span></span><br><span class="line">save_path = <span class="string">&#x27;F:\\Python\\Transformer\\demo\\model\\trade_Transformer_LSTM\\in\\&#x27;</span></span><br><span class="line">os.makedirs(os.path.dirname(save_path), exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">torch.save(model.state_dict(), save_path+<span class="string">&#x27;model_price.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 5: 评估最佳模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;开始验证...&quot;</span>)</span><br><span class="line">model.load_state_dict(torch.load(save_path+<span class="string">&#x27;model_price.pth&#x27;</span>))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">all_preds = []</span><br><span class="line">all_true = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> x_cat_batch, x_cont_batch, y_batch <span class="keyword">in</span> test_loader:</span><br><span class="line">        x_cat_batch = x_cat_batch.to(device)</span><br><span class="line">        x_cont_batch = x_cont_batch.to(device)</span><br><span class="line"></span><br><span class="line">        outputs = model(x_cat_batch, x_cont_batch)</span><br><span class="line"></span><br><span class="line">        all_preds.append(outputs.cpu().numpy())</span><br><span class="line">        all_true.append(y_batch.cpu().numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并所有批次的结果</span></span><br><span class="line">y_pred = np.concatenate(all_preds, axis=<span class="number">0</span>)</span><br><span class="line">y_true = np.concatenate(all_true, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反标准化 + exp</span></span><br><span class="line">y_pred_unscaled = np.expm1(scaler_y.inverse_transform(y_pred))</span><br><span class="line">y_true_unscaled = np.expm1(scaler_y.inverse_transform(y_true))</span><br><span class="line"></span><br><span class="line">pred_renminbi = y_pred_unscaled</span><br><span class="line"></span><br><span class="line">true_renminbi = y_true_unscaled</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">name, true, pred</span>):</span><br><span class="line">    r2 = r2_score(true, pred)</span><br><span class="line">    mae = np.mean(np.<span class="built_in">abs</span>(true - pred))</span><br><span class="line">    mse = np.mean((true - pred) ** <span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;name&#125;</span> 评估:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;R² Score: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;MSE: <span class="subst">&#123;mse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;MAE: <span class="subst">&#123;mae:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> r2, mse, mae</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数量评估</span></span><br><span class="line">r2_q, mse_q, mae_q = evaluate(<span class="string">&quot;单价&quot;</span>, true_renminbi, pred_renminbi)</span><br><span class="line">logging.basicConfig(filename=<span class="string">&#x27;training_Trade_Transformer_Price.log&#x27;</span>, level=logging.INFO)</span><br><span class="line">time = datetime.now().strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">logging.info(<span class="string">f&quot;datetime:<span class="subst">&#123;datetime&#125;</span>, R2:<span class="subst">&#123;r2_q&#125;</span>, MSE:<span class="subst">&#123;mse_q&#125;</span>, MAE:<span class="subst">&#123;mae_q&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印部分样本</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n部分预测值 VS 真实值:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;预测: 单价=<span class="subst">&#123;pred_renminbi[i].item():<span class="number">.2</span>f&#125;</span>&quot;</span></span><br><span class="line">          <span class="string">f&quot;真实: 单价=<span class="subst">&#123;true_renminbi[i].item():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 绘图部分 ---</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制预测 vs 真实曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(true_renminbi, label=<span class="string">&#x27;真实单价&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(pred_renminbi, label=<span class="string">&#x27;预测单价&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;单价：预测值 vs 真实值&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;样本索引&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;单价&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.annotate(<span class="string">f&#x27;R2=<span class="subst">&#123;r2_q:<span class="number">.3</span>f&#125;</span>&#x27;</span>, xy=(<span class="number">0.05</span>, <span class="number">0.9</span>), xycoords=<span class="string">&#x27;axes fraction&#x27;</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.annotate(<span class="string">f&#x27;MSE=<span class="subst">&#123;mse_q:<span class="number">.3</span>f&#125;</span>&#x27;</span>, xy=(<span class="number">0.05</span>, <span class="number">0.8</span>), xycoords=<span class="string">&#x27;axes fraction&#x27;</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.annotate(<span class="string">f&#x27;MAE=<span class="subst">&#123;mae_q:<span class="number">.3</span>f&#125;</span>&#x27;</span>, xy=(<span class="number">0.05</span>, <span class="number">0.7</span>), xycoords=<span class="string">&#x27;axes fraction&#x27;</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(save_path+<span class="string">&#x27;predicted_vs_true_price.png&#x27;</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制误差分布直方图</span></span><br><span class="line">errors = y_true.flatten() - y_pred.flatten()</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">plt.hist(errors, bins=<span class="number">30</span>, color=<span class="string">&#x27;skyblue&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.axvline(<span class="number">0</span>, color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;dashed&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;预测误差分布&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;误差 = 真实值 - 预测值&quot;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;频数&quot;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(save_path+<span class="string">&#x27;error_distribution_price.png&#x27;</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制 Loss 曲线（训练过程中记录的 losses）</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(losses, label=<span class="string">&#x27;Training Loss&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(val_losses, label=<span class="string">&#x27;Validation Loss&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss (MSE)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;训练损失曲线&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(save_path+<span class="string">&#x27;training_loss_curve_price.png&#x27;</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存 scaler 和 label encoders</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(save_path+<span class="string">&#x27;scaler_X_price.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(scaler_X, f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(save_path+<span class="string">&#x27;scaler_y_price.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(scaler_y, f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(save_path+<span class="string">&#x27;label_encoders_price.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(label_encoders, f)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 模型和预处理器已成功保存！&quot;</span>)</span><br><span class="line"><span class="comment"># 同步播放（程序会暂停直到播放结束）</span></span><br><span class="line">winsound.PlaySound(<span class="string">&quot;F:\\Python\\训练完成.wav&quot;</span>, winsound.SND_FILENAME)</span><br></pre></td></tr></table></figure>

<h4 id="2-Trade-Transformer-LSTM-quantity-py"><a href="#2-Trade-Transformer-LSTM-quantity-py" class="headerlink" title="2.Trade_Transformer_LSTM_quantity.py"></a>2.Trade_Transformer_LSTM_quantity.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> winsound</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: 加载和预处理数据</span></span><br><span class="line"><span class="comment">#file_path = &#x27;F:\Python\Transformer\demo\data\进口\merged_output.csv&#x27;</span></span><br><span class="line">file_path = <span class="string">&#x27;F:\Python\Transformer\demo\data\出口\merged_output.csv&#x27;</span></span><br><span class="line"><span class="comment">#file_path = &#x27;E:\\admin\\Desktop\\2.csv&#x27;</span></span><br><span class="line">df = pd.read_csv(file_path, encoding=<span class="string">&#x27;UTF-8&#x27;</span>, thousands=<span class="string">&#x27;,&#x27;</span>, low_memory=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取年月列</span></span><br><span class="line">df[<span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>).<span class="built_in">str</span>[:<span class="number">4</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>).<span class="built_in">str</span>[<span class="number">4</span>:].astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征列调整</span></span><br><span class="line">categorical_cols = [<span class="string">&#x27;贸易伙伴编码&#x27;</span>, <span class="string">&#x27;商品编码&#x27;</span>, <span class="string">&#x27;贸易方式编码&#x27;</span>, <span class="string">&#x27;注册地编码&#x27;</span>, <span class="string">&#x27;计量单位&#x27;</span>]</span><br><span class="line">continuous_cols = [<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;数量&#x27;</span>, <span class="string">&#x27;人民币&#x27;</span>]  <span class="comment"># 包含连续变量（已包含年月）</span></span><br><span class="line">target_cols = [<span class="string">&#x27;数量&#x27;</span>]   <span class="comment"># 原始目标变量名</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理数据</span></span><br><span class="line">df[target_cols] = df[target_cols].replace(&#123;<span class="string">&#x27;-&#x27;</span>: np.nan, <span class="string">&#x27;&#x27;</span>: np.nan&#125;, regex=<span class="literal">False</span>)</span><br><span class="line">df[target_cols] = df[target_cols].apply(pd.to_numeric, errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在清洗完数据之后、标准化之前添加：</span></span><br><span class="line">df[target_cols] = df[target_cols].clip(lower=<span class="number">0</span>)  <span class="comment"># 先确保非负</span></span><br><span class="line">df[<span class="string">&#x27;log_数量&#x27;</span>] = np.log1p(df[<span class="string">&#x27;数量&#x27;</span>])</span><br><span class="line">target_cols_log = [<span class="string">&#x27;log_数量&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化 log 变换后的目标变量</span></span><br><span class="line">scaler_y = StandardScaler()</span><br><span class="line">df[target_cols_log] = scaler_y.fit_transform(df[target_cols_log])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理连续变量中的异常值</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> continuous_cols:</span><br><span class="line">    df[col] = df[col].replace(&#123;<span class="string">&#x27;-&#x27;</span>: np.nan, <span class="string">&#x27;&#x27;</span>: np.nan&#125;, regex=<span class="literal">False</span>)</span><br><span class="line">    df[col] = pd.to_numeric(df[col], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除含有 NaN 的行（包括类别、连续和目标变量）</span></span><br><span class="line">df.dropna(subset=categorical_cols + continuous_cols + target_cols_log, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对类别变量做 Label Encoding</span></span><br><span class="line">label_encoders = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols:</span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    df[col] = le.fit_transform(df[col].astype(<span class="built_in">str</span>))  <span class="comment"># 强制转字符串防止报错</span></span><br><span class="line">    label_encoders[col] = le</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化连续变量（包括 year 和 month）</span></span><br><span class="line">scaler_X = StandardScaler()</span><br><span class="line">df[continuous_cols] = scaler_X.fit_transform(df[continuous_cols])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按商品分组创建时间序列</span></span><br><span class="line">grouped = df.groupby(<span class="string">&#x27;商品编码&#x27;</span>)</span><br><span class="line">sequences = []</span><br><span class="line">seq_length = <span class="number">12</span><span class="comment">#历史窗口长度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, group <span class="keyword">in</span> grouped:</span><br><span class="line">    group = group.sort_values([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;month&#x27;</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(group) &lt; seq_length + <span class="number">1</span>:  <span class="comment"># 确保有足够数据点</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建序列</span></span><br><span class="line">    X_cat_group = group[categorical_cols].values</span><br><span class="line">    X_cont_group = group[continuous_cols].values</span><br><span class="line">    y_group = group[target_cols_log].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_cat_group) - seq_length):</span><br><span class="line">        x_cat_seq = X_cat_group[i:i + seq_length]</span><br><span class="line">        x_cont_seq = X_cont_group[i:i + seq_length]</span><br><span class="line">        y_val = y_group[i + seq_length]</span><br><span class="line">        sequences.append((x_cat_seq, x_cont_seq, y_val))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为数组</span></span><br><span class="line"><span class="keyword">if</span> sequences:</span><br><span class="line">    X_cat, X_cont, y = <span class="built_in">zip</span>(*sequences)</span><br><span class="line">    X_cat = np.array(X_cat)</span><br><span class="line">    X_cont = np.array(X_cont)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">&quot;没有足够数据创建序列，请检查数据或减小seq_length&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割训练集和测试集（不打乱）</span></span><br><span class="line">X_cat_train, X_cat_test, X_cont_train, X_cont_test, y_train, y_test = train_test_split(</span><br><span class="line">    X_cat, X_cont, y, test_size=<span class="number">0.2</span>, shuffle=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为PyTorch张量</span></span><br><span class="line">X_cat_train_tensor = torch.tensor(X_cat_train, dtype=torch.long)</span><br><span class="line">X_cont_train_tensor = torch.tensor(X_cont_train, dtype=torch.float32)</span><br><span class="line">y_train_tensor = torch.tensor(y_train, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">X_cat_test_tensor = torch.tensor(X_cat_test, dtype=torch.long)</span><br><span class="line">X_cont_test_tensor = torch.tensor(X_cont_test, dtype=torch.float32)</span><br><span class="line">y_test_tensor = torch.tensor(y_test, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataLoader</span></span><br><span class="line">train_dataset = torch.utils.data.TensorDataset(X_cat_train_tensor, X_cont_train_tensor, y_train_tensor)</span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)  <span class="comment"># 增大batch_size</span></span><br><span class="line">test_dataset = torch.utils.data.TensorDataset(X_cat_test_tensor, X_cont_test_tensor, y_test_tensor)</span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_dataset,</span><br><span class="line">    batch_size=<span class="number">32</span>,   <span class="comment"># 小批量验证</span></span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    num_workers=<span class="number">0</span>,</span><br><span class="line">    pin_memory=<span class="literal">False</span> <span class="keyword">if</span> <span class="keyword">not</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">CheckPointModelPath = <span class="string">&#x27;F:\\Python\\Transformer\\demo\\model\\trade_Transformer_LSTM\\out\\checkpoint_quantity.pth&#x27;</span></span><br><span class="line"><span class="comment">#CheckPointModelPath = &#x27;F:\\Python\\Transformer\\demo\\model\\temp\\in\\checkpoint_quantity.pth&#x27;</span></span><br><span class="line"><span class="comment">#早停机制类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EarlyStopping</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patience=<span class="number">10</span>, verbose=<span class="literal">False</span>, delta=<span class="number">0</span>, path=CheckPointModelPath</span>):</span><br><span class="line">        <span class="variable language_">self</span>.patience = patience</span><br><span class="line">        <span class="variable language_">self</span>.verbose = verbose</span><br><span class="line">        <span class="variable language_">self</span>.counter = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.best_score = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.early_stop = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.val_loss_min = np.Inf</span><br><span class="line">        <span class="variable language_">self</span>.delta = delta</span><br><span class="line">        <span class="variable language_">self</span>.path = path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, val_loss, model</span>):</span><br><span class="line">        score = -val_loss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.best_score <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>.best_score = score</span><br><span class="line">            <span class="variable language_">self</span>.save_checkpoint(val_loss, model)</span><br><span class="line">        <span class="keyword">elif</span> score &lt; <span class="variable language_">self</span>.best_score + <span class="variable language_">self</span>.delta:</span><br><span class="line">            <span class="variable language_">self</span>.counter += <span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;EarlyStopping counter: <span class="subst">&#123;self.counter&#125;</span> out of <span class="subst">&#123;self.patience&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.counter &gt;= <span class="variable language_">self</span>.patience:</span><br><span class="line">                <span class="variable language_">self</span>.early_stop = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.best_score = score</span><br><span class="line">            <span class="variable language_">self</span>.save_checkpoint(val_loss, model)</span><br><span class="line">            <span class="variable language_">self</span>.counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_checkpoint</span>(<span class="params">self, val_loss, model</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.verbose:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Validation loss decreased (<span class="subst">&#123;self.val_loss_min:<span class="number">.6</span>f&#125;</span> --&gt; <span class="subst">&#123;val_loss:<span class="number">.6</span>f&#125;</span>). Saving model...&#x27;</span>)</span><br><span class="line">        torch.save(model.state_dict(), <span class="variable language_">self</span>.path)</span><br><span class="line">        <span class="variable language_">self</span>.val_loss_min = val_loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方案一：使用可学习的位置编码</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LearnablePositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.position_embeddings = nn.Embedding(max_len, d_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        positions = torch.arange(<span class="number">0</span>, x.size(<span class="number">1</span>), device=x.device).expand(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = x + <span class="variable language_">self</span>.position_embeddings(positions)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 混合 LSTM + Transformer 模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LSTMTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_embeddings_list, continuous_dim, model_dim=<span class="number">64</span>, hidden_size=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">4</span>, num_layers=<span class="number">2</span>, dropout=<span class="number">0.3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.cat_embeddings = nn.ModuleList([</span><br><span class="line">            nn.Embedding(num_emb, model_dim) <span class="keyword">for</span> num_emb <span class="keyword">in</span> num_embeddings_list</span><br><span class="line">        ])</span><br><span class="line">        <span class="variable language_">self</span>.cont_proj = nn.Linear(continuous_dim, model_dim)</span><br><span class="line">        <span class="variable language_">self</span>.pos_encoder = LearnablePositionalEncoding(model_dim)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.lstm = nn.LSTM(model_dim, hidden_size, batch_first=<span class="literal">True</span>, bidirectional=<span class="literal">False</span>)</span><br><span class="line">        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.norm = nn.LayerNorm(hidden_size)</span><br><span class="line">        <span class="variable language_">self</span>.fc_out = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, cat_inputs, cont_inputs</span>):</span><br><span class="line">        <span class="comment"># Embeddings</span></span><br><span class="line">        embedded_cat = torch.stack([emb(cat_inputs[:, :, i]) <span class="keyword">for</span> i, emb <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.cat_embeddings)], dim=<span class="number">0</span>).<span class="built_in">sum</span>(dim=<span class="number">0</span>)</span><br><span class="line">        embedded_cont = <span class="variable language_">self</span>.cont_proj(cont_inputs)</span><br><span class="line">        x = embedded_cat + embedded_cont</span><br><span class="line">        x = <span class="variable language_">self</span>.pos_encoder(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># LSTM</span></span><br><span class="line">        x, _ = <span class="variable language_">self</span>.lstm(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Transformer</span></span><br><span class="line">        x = x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)  <span class="comment"># [S, B, D]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.transformer(x)</span><br><span class="line">        x = x.mean(dim=<span class="number">0</span>)  <span class="comment"># 时间维度平均</span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc_out(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: 初始化模型 &amp; 训练</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取每个类别特征的唯一值数量</span></span><br><span class="line">num_embeddings_list = [df[col].nunique() <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols]</span><br><span class="line"></span><br><span class="line">model = LSTMTransformer(</span><br><span class="line">    num_embeddings_list=[df[col].nunique() <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols],</span><br><span class="line">    continuous_dim=<span class="built_in">len</span>(continuous_cols),</span><br><span class="line">    model_dim=<span class="number">128</span>,<span class="comment">#输入维度大小</span></span><br><span class="line">    hidden_size=<span class="number">128</span>,<span class="comment">#隐藏层大小</span></span><br><span class="line">    num_heads=<span class="number">16</span>,<span class="comment">#注意力头数</span></span><br><span class="line">    num_layers=<span class="number">5</span>,<span class="comment">#Transformer层的数量</span></span><br><span class="line">    dropout=<span class="number">0.6</span></span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss(<span class="number">1.0</span>)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>, weight_decay=<span class="number">1e-5</span>)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&#x27;min&#x27;</span>, factor=<span class="number">0.5</span>, patience=<span class="number">5</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">150</span></span><br><span class="line">best_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">losses = []</span><br><span class="line">val_losses = []</span><br><span class="line"></span><br><span class="line">early_stopping = EarlyStopping(patience=<span class="number">100</span>, verbose=<span class="literal">True</span>)<span class="comment">#patience表示耐心程度，当连续多少个epoch without improvement时，停止训练</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;开始训练...&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    model.train()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    loop = tqdm(train_loader, desc=<span class="string">f&quot;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x_cat_batch, x_cont_batch, y_batch <span class="keyword">in</span> loop:</span><br><span class="line">        x_cat_batch, x_cont_batch, y_batch = x_cat_batch.to(device), x_cont_batch.to(device), y_batch.to(device)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(x_cat_batch, x_cont_batch)</span><br><span class="line">        loss = criterion(outputs, y_batch)</span><br><span class="line">        loss.backward()</span><br><span class="line">        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)  <span class="comment"># 防止梯度爆炸</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        loop.set_postfix(loss=loss.item())</span><br><span class="line"></span><br><span class="line">    avg_train_loss = total_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">    losses.append(avg_train_loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    val_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> x_cat_val, x_cont_val, y_val <span class="keyword">in</span> test_loader:</span><br><span class="line">            x_cat_val, x_cont_val, y_val = x_cat_val.to(device), x_cont_val.to(device), y_val.to(device)</span><br><span class="line">            val_outputs = model(x_cat_val, x_cont_val)</span><br><span class="line">            loss = criterion(val_outputs, y_val)</span><br><span class="line">            val_loss += loss.item() * x_cat_val.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        val_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    scheduler.step(val_loss)</span><br><span class="line">    val_losses.append(val_loss)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span> | Train Loss: <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span> | Val Loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    logging.basicConfig(filename=<span class="string">&#x27;training_Trade_Transformer_Quantity.log&#x27;</span>, level=logging.INFO)</span><br><span class="line">    logging.info(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>, Train Loss: <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span>, Val Loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    early_stopping(val_loss, model)</span><br><span class="line">    <span class="keyword">if</span> early_stopping.early_stop:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Early stopping&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  保存模型</span></span><br><span class="line">save_path = <span class="string">&#x27;F:\\Python\\Transformer\\demo\\model\\trade_Transformer_LSTM\\out\\&#x27;</span></span><br><span class="line"><span class="comment">#save_path = &#x27;F:\\Python\\Transformer\\demo\\model\\temp\\in\\&#x27;</span></span><br><span class="line">os.makedirs(os.path.dirname(save_path), exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">torch.save(model.state_dict(), save_path+<span class="string">&#x27;model_quantity.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 5: 评估最佳模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;开始验证...&quot;</span>)</span><br><span class="line">model.load_state_dict(torch.load(save_path+<span class="string">&#x27;model_quantity.pth&#x27;</span>))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">all_preds = []</span><br><span class="line">all_true = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> x_cat_batch, x_cont_batch, y_batch <span class="keyword">in</span> test_loader:</span><br><span class="line">        x_cat_batch = x_cat_batch.to(device)</span><br><span class="line">        x_cont_batch = x_cont_batch.to(device)</span><br><span class="line"></span><br><span class="line">        outputs = model(x_cat_batch, x_cont_batch)</span><br><span class="line"></span><br><span class="line">        all_preds.append(outputs.cpu().numpy())</span><br><span class="line">        all_true.append(y_batch.cpu().numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并所有批次的结果</span></span><br><span class="line">y_pred = np.concatenate(all_preds, axis=<span class="number">0</span>)</span><br><span class="line">y_true = np.concatenate(all_true, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反标准化 + exp</span></span><br><span class="line">y_pred_unscaled = np.expm1(scaler_y.inverse_transform(y_pred))</span><br><span class="line">y_true_unscaled = np.expm1(scaler_y.inverse_transform(y_true))</span><br><span class="line"></span><br><span class="line">pred_quantity = y_pred_unscaled</span><br><span class="line"></span><br><span class="line">true_quantity = y_true_unscaled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算指标</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">name, true, pred</span>):</span><br><span class="line">    r2 = r2_score(true, pred)</span><br><span class="line">    mae = np.mean(np.<span class="built_in">abs</span>(true - pred))</span><br><span class="line">    mse = np.mean((true - pred) ** <span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;name&#125;</span> 评估:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;R² Score: <span class="subst">&#123;r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;MSE: <span class="subst">&#123;mse:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;MAE: <span class="subst">&#123;mae:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> r2, mse, mae</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数量评估</span></span><br><span class="line">r2_q, mse_q, mae_q = evaluate(<span class="string">&quot;数量&quot;</span>, true_quantity, pred_quantity)</span><br><span class="line">logging.basicConfig(filename=<span class="string">&#x27;training_Trade_Transformer_Quantity.log&#x27;</span>, level=logging.INFO)</span><br><span class="line">time = datetime.now().strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">logging.info(<span class="string">f&quot;datetime:<span class="subst">&#123;datetime&#125;</span>, R2:<span class="subst">&#123;r2_q&#125;</span>, MSE:<span class="subst">&#123;mse_q&#125;</span>, MAE:<span class="subst">&#123;mae_q&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印部分样本</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n部分预测值 VS 真实值:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;预测: 数量=<span class="subst">&#123;pred_quantity[i].item():<span class="number">.2</span>f&#125;</span>&quot;</span></span><br><span class="line">          <span class="string">f&quot;真实: 数量=<span class="subst">&#123;true_quantity[i].item():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 绘图部分 ---</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制预测 vs 真实曲线</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(true_quantity, label=<span class="string">&#x27;真实数量&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(pred_quantity, label=<span class="string">&#x27;预测数量&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;数量：预测值 vs 真实值&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;样本索引&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;数量&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.annotate(<span class="string">f&#x27;R2=<span class="subst">&#123;r2_q:<span class="number">.3</span>f&#125;</span>&#x27;</span>, xy=(<span class="number">0.05</span>, <span class="number">0.9</span>), xycoords=<span class="string">&#x27;axes fraction&#x27;</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.annotate(<span class="string">f&#x27;MSE=<span class="subst">&#123;mse_q:<span class="number">.3</span>f&#125;</span>&#x27;</span>, xy=(<span class="number">0.05</span>, <span class="number">0.8</span>), xycoords=<span class="string">&#x27;axes fraction&#x27;</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.annotate(<span class="string">f&#x27;MAE=<span class="subst">&#123;mae_q:<span class="number">.3</span>f&#125;</span>&#x27;</span>, xy=(<span class="number">0.05</span>, <span class="number">0.7</span>), xycoords=<span class="string">&#x27;axes fraction&#x27;</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(save_path+<span class="string">&#x27;predicted_vs_true_quantity.png&#x27;</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制误差分布直方图</span></span><br><span class="line">errors = y_true.flatten() - y_pred.flatten()</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">plt.hist(errors, bins=<span class="number">30</span>, color=<span class="string">&#x27;skyblue&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">plt.axvline(<span class="number">0</span>, color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;dashed&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;预测误差分布&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;误差 = 真实值 - 预测值&quot;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;频数&quot;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(save_path+<span class="string">&#x27;error_distribution_quantity.png&#x27;</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制 Loss 曲线（训练过程中记录的 losses）</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(losses, label=<span class="string">&#x27;Training Loss&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(val_losses, label=<span class="string">&#x27;Validation Loss&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss (MSE)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;训练损失曲线&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(save_path+<span class="string">&#x27;training_loss_curve_quantity.png&#x27;</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存 scaler 和 label encoders</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(save_path+<span class="string">&#x27;scaler_X_quantity.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(scaler_X, f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(save_path+<span class="string">&#x27;scaler_y_quantity.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(scaler_y, f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(save_path+<span class="string">&#x27;label_encoders_quantity.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(label_encoders, f)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 模型和预处理器已成功保存！&quot;</span>)</span><br><span class="line"><span class="comment"># 同步播放（程序会暂停直到播放结束）</span></span><br><span class="line">winsound.PlaySound(<span class="string">&quot;F:\\Python\\训练完成.wav&quot;</span>, winsound.SND_FILENAME)</span><br></pre></td></tr></table></figure>

<h4 id="3-app-py-Trade-FlaskApp-Transformer-py"><a href="#3-app-py-Trade-FlaskApp-Transformer-py" class="headerlink" title="3.app.py/Trade_FlaskApp_Transformer.py"></a>3.app.py/Trade_FlaskApp_Transformer.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, request, jsonify</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型参数</span></span><br><span class="line"><span class="comment"># 进口</span></span><br><span class="line"><span class="comment"># 单价</span></span><br><span class="line">IN_PRICE_MODEL_PATH = <span class="string">&#x27;model/trade_Transformer/in/model_price.pth&#x27;</span></span><br><span class="line">IN_PRICE_SCALER_X_PATH = <span class="string">&#x27;model/trade_Transformer/in/scaler_X_price.pkl&#x27;</span></span><br><span class="line">IN_PRICE_SCALER_Y_PATH = <span class="string">&#x27;model/trade_Transformer/in/scaler_y_price.pkl&#x27;</span></span><br><span class="line">IN_PRICE_LABEL_ENCODERS_PATH = <span class="string">&#x27;model/trade_Transformer/in/label_encoders_price.pkl&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数量</span></span><br><span class="line">IN_QUANTITY_MODEL_PATH = <span class="string">&#x27;model/trade_Transformer/in/model_quantity.pth&#x27;</span></span><br><span class="line">IN_QUANTITY_SCALER_X_PATH = <span class="string">&#x27;model/trade_Transformer/in/scaler_X_quantity.pkl&#x27;</span></span><br><span class="line">IN_QUANTITY_SCALER_Y_PATH = <span class="string">&#x27;model/trade_Transformer/in/scaler_y_quantity.pkl&#x27;</span></span><br><span class="line">IN_QUANTITY_LABEL_ENCODERS_PATH = <span class="string">&#x27;model/trade_Transformer/in/label_encoders_quantity.pkl&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 出口</span></span><br><span class="line"><span class="comment"># 单价</span></span><br><span class="line">OUT_PRICE_MODEL_PATH = <span class="string">&#x27;model/trade_Transformer/out/model_price.pth&#x27;</span></span><br><span class="line">OUT_PRICE_SCALER_X_PATH = <span class="string">&#x27;model/trade_Transformer/out/scaler_X_price.pkl&#x27;</span></span><br><span class="line">OUT_PRICE_SCALER_Y_PATH = <span class="string">&#x27;model/trade_Transformer/out/scaler_y_price.pkl&#x27;</span></span><br><span class="line">OUT_PRICE_LABEL_ENCODERS_PATH = <span class="string">&#x27;model/trade_Transformer/out/label_encoders_price.pkl&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数量</span></span><br><span class="line">OUT_QUANTITY_MODEL_PATH = <span class="string">&#x27;model/trade_Transformer/out/model_quantity.pth&#x27;</span></span><br><span class="line">OUT_QUANTITY_SCALER_X_PATH = <span class="string">&#x27;model/trade_Transformer/out/scaler_X_quantity.pkl&#x27;</span></span><br><span class="line">OUT_QUANTITY_SCALER_Y_PATH = <span class="string">&#x27;model/trade_Transformer/out/scaler_y_quantity.pkl&#x27;</span></span><br><span class="line">OUT_QUANTITY_LABEL_ENCODERS_PATH = <span class="string">&#x27;model/trade_Transformer/out/label_encoders_quantity.pkl&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义类别特征列和连续特征列（必须与训练时一致）</span></span><br><span class="line">categorical_cols = [<span class="string">&#x27;贸易伙伴编码&#x27;</span>, <span class="string">&#x27;商品编码&#x27;</span>, <span class="string">&#x27;贸易方式编码&#x27;</span>, <span class="string">&#x27;注册地编码&#x27;</span>, <span class="string">&#x27;计量单位&#x27;</span>]</span><br><span class="line">continuous_cols = [<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;数量&#x27;</span>, <span class="string">&#x27;人民币&#x27;</span>]</span><br><span class="line">seq_length = <span class="number">12</span>  <span class="comment"># 时间序列长度，必须与训练时一致</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 scaler 和 label encoders</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(IN_PRICE_SCALER_X_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    in_price_scaler_X = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(IN_PRICE_SCALER_Y_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    in_price_scaler_y = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(IN_PRICE_LABEL_ENCODERS_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    in_price_label_encoders = pickle.load(f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(IN_QUANTITY_SCALER_X_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    in_quantity_scaler_X = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(IN_QUANTITY_SCALER_Y_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    in_quantity_scaler_y = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(IN_QUANTITY_LABEL_ENCODERS_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    in_quantity_label_encoders = pickle.load(f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(OUT_PRICE_SCALER_X_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    out_price_scaler_X = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(OUT_PRICE_SCALER_Y_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    out_price_scaler_y = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(OUT_PRICE_LABEL_ENCODERS_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    out_price_label_encoders = pickle.load(f)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(OUT_QUANTITY_SCALER_X_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    out_quantity_scaler_X = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(OUT_QUANTITY_SCALER_Y_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    out_quantity_scaler_y = pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(OUT_QUANTITY_LABEL_ENCODERS_PATH, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    out_quantity_label_encoders = pickle.load(f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型结构（必须与训练时一致）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LearnablePositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.position_embeddings = nn.Embedding(max_len, d_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        positions = torch.arange(<span class="number">0</span>, x.size(<span class="number">1</span>), device=x.device).expand(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = x + <span class="variable language_">self</span>.position_embeddings(positions)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LSTMTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_embeddings_list, continuous_dim, model_dim=<span class="number">64</span>, hidden_size=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">4</span>, num_layers=<span class="number">2</span>, dropout=<span class="number">0.3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.cat_embeddings = nn.ModuleList([</span><br><span class="line">            nn.Embedding(num_emb, model_dim) <span class="keyword">for</span> num_emb <span class="keyword">in</span> num_embeddings_list</span><br><span class="line">        ])</span><br><span class="line">        <span class="variable language_">self</span>.cont_proj = nn.Linear(continuous_dim, model_dim)</span><br><span class="line">        <span class="variable language_">self</span>.pos_encoder = LearnablePositionalEncoding(model_dim)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.lstm = nn.LSTM(model_dim, hidden_size, batch_first=<span class="literal">True</span>, bidirectional=<span class="literal">False</span>)</span><br><span class="line">        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.norm = nn.LayerNorm(hidden_size)</span><br><span class="line">        <span class="variable language_">self</span>.fc_out = nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, cat_inputs, cont_inputs</span>):</span><br><span class="line">        <span class="comment"># Embeddings</span></span><br><span class="line">        embedded_cat = torch.stack([emb(cat_inputs[:, :, i]) <span class="keyword">for</span> i, emb <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.cat_embeddings)], dim=<span class="number">0</span>).<span class="built_in">sum</span>(dim=<span class="number">0</span>)</span><br><span class="line">        embedded_cont = <span class="variable language_">self</span>.cont_proj(cont_inputs)</span><br><span class="line">        x = embedded_cat + embedded_cont</span><br><span class="line">        x = <span class="variable language_">self</span>.pos_encoder(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># LSTM</span></span><br><span class="line">        x, _ = <span class="variable language_">self</span>.lstm(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Transformer</span></span><br><span class="line">        x = x.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)  <span class="comment"># [S, B, D]</span></span><br><span class="line">        x = <span class="variable language_">self</span>.transformer(x)</span><br><span class="line">        x = x.mean(dim=<span class="number">0</span>)  <span class="comment"># 时间维度平均</span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc_out(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化模型并加载权重</span></span><br><span class="line">num_embeddings_list_in_price = [in_price_label_encoders[col].classes_.shape[<span class="number">0</span>] <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols]</span><br><span class="line">model_in_price = LSTMTransformer(</span><br><span class="line">    num_embeddings_list=num_embeddings_list_in_price,</span><br><span class="line">    continuous_dim=<span class="built_in">len</span>(continuous_cols),</span><br><span class="line">    model_dim=<span class="number">128</span>,</span><br><span class="line">    hidden_size=<span class="number">64</span>,</span><br><span class="line">    num_heads=<span class="number">8</span>,</span><br><span class="line">    num_layers=<span class="number">4</span>,</span><br><span class="line">    dropout=<span class="number">0.6</span></span><br><span class="line">)</span><br><span class="line">model_in_price.load_state_dict(torch.load(IN_PRICE_MODEL_PATH, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">model_in_price.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">num_embeddings_list_in_quantity = [in_quantity_label_encoders[col].classes_.shape[<span class="number">0</span>] <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols]</span><br><span class="line">model_in_quantity = LSTMTransformer(</span><br><span class="line">    num_embeddings_list=num_embeddings_list_in_quantity,</span><br><span class="line">    continuous_dim=<span class="built_in">len</span>(continuous_cols),</span><br><span class="line">    model_dim=<span class="number">128</span>,  <span class="comment"># 输入维度大小</span></span><br><span class="line">    hidden_size=<span class="number">128</span>,  <span class="comment"># 隐藏层大小</span></span><br><span class="line">    num_heads=<span class="number">16</span>,  <span class="comment"># 注意力头数</span></span><br><span class="line">    num_layers=<span class="number">5</span>,  <span class="comment"># Transformer层的数量</span></span><br><span class="line">    dropout=<span class="number">0.6</span></span><br><span class="line">)</span><br><span class="line">model_in_quantity.load_state_dict(torch.load(IN_QUANTITY_MODEL_PATH, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">model_in_quantity.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">num_embeddings_list_out_price = [out_price_label_encoders[col].classes_.shape[<span class="number">0</span>] <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols]</span><br><span class="line">model_out_price = LSTMTransformer(</span><br><span class="line">    num_embeddings_list=num_embeddings_list_out_price,</span><br><span class="line">    continuous_dim=<span class="built_in">len</span>(continuous_cols),</span><br><span class="line">    model_dim=<span class="number">64</span>,</span><br><span class="line">    hidden_size=<span class="number">64</span>,</span><br><span class="line">    num_heads=<span class="number">8</span>,</span><br><span class="line">    num_layers=<span class="number">4</span>,</span><br><span class="line">    dropout=<span class="number">0.6</span></span><br><span class="line">)</span><br><span class="line">model_out_price.load_state_dict(torch.load(OUT_PRICE_MODEL_PATH, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">model_out_price.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">num_embeddings_list_out_quantity = [out_quantity_label_encoders[col].classes_.shape[<span class="number">0</span>] <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols]</span><br><span class="line">model_out_quantity = LSTMTransformer(</span><br><span class="line">    num_embeddings_list=num_embeddings_list_out_quantity,</span><br><span class="line">    continuous_dim=<span class="built_in">len</span>(continuous_cols),</span><br><span class="line">    model_dim=<span class="number">64</span>,  <span class="comment"># 输入维度大小</span></span><br><span class="line">    hidden_size=<span class="number">64</span>,  <span class="comment"># 隐藏层大小</span></span><br><span class="line">    num_heads=<span class="number">8</span>,  <span class="comment"># 注意力头数</span></span><br><span class="line">    num_layers=<span class="number">4</span>,  <span class="comment"># Transformer层的数量</span></span><br><span class="line">    dropout=<span class="number">0.6</span></span><br><span class="line">)</span><br><span class="line">model_out_quantity.load_state_dict(torch.load(OUT_QUANTITY_MODEL_PATH, map_location=<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">model_out_quantity.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据库连接配置</span></span><br><span class="line"><span class="comment"># 开发环境</span></span><br><span class="line">db_config = &#123;</span><br><span class="line">    <span class="string">&#x27;host&#x27;</span>: <span class="string">&#x27;localhost&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;user&#x27;</span>: <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;751225hzx&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;database&#x27;</span>: <span class="string">&#x27;trade&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;charset&#x27;</span>: <span class="string">&#x27;utf8mb4&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生产环境</span></span><br><span class="line"><span class="comment"># db_config = &#123;</span></span><br><span class="line"><span class="comment">#     &#x27;host&#x27;: &#x27;localhost&#x27;,</span></span><br><span class="line"><span class="comment">#     &#x27;user&#x27;: &#x27;trade&#x27;,</span></span><br><span class="line"><span class="comment">#     &#x27;password&#x27;: &#x27;123456&#x27;,</span></span><br><span class="line"><span class="comment">#     &#x27;database&#x27;: &#x27;trade&#x27;,</span></span><br><span class="line"><span class="comment">#     &#x27;charset&#x27;: &#x27;utf8mb4&#x27;</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">db_process</span>(<span class="params"><span class="built_in">type</span></span>):</span><br><span class="line">    request_data = request.get_json(force=<span class="literal">True</span>)</span><br><span class="line">    friend = request_data.get(<span class="string">&#x27;贸易伙伴名称&#x27;</span>)</span><br><span class="line">    good = request_data.get(<span class="string">&#x27;商品名称&#x27;</span>)</span><br><span class="line">    trade = request_data.get(<span class="string">&#x27;贸易方式&#x27;</span>)</span><br><span class="line">    register = request_data.get(<span class="string">&#x27;注册地名称&#x27;</span>)</span><br><span class="line">    year = request_data.get(<span class="string">&#x27;year&#x27;</span>)</span><br><span class="line">    month = request_data.get(<span class="string">&#x27;month&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建目标日期</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        target_date = datetime(year=<span class="built_in">int</span>(year), month=<span class="built_in">int</span>(month), day=<span class="number">1</span>).strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">&#x27;无效的年/月&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># SQL 查询语句</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span> == <span class="string">&quot;in&quot;</span>:</span><br><span class="line">        query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                SELECT * </span></span><br><span class="line"><span class="string">                FROM trade_in </span></span><br><span class="line"><span class="string">                WHERE 贸易伙伴名称 = %s</span></span><br><span class="line"><span class="string">                  AND 商品名称 = %s</span></span><br><span class="line"><span class="string">                  AND 贸易方式名称 = %s</span></span><br><span class="line"><span class="string">                  AND 注册地名称 = %s</span></span><br><span class="line"><span class="string">                  AND 数据年月 &lt; %s</span></span><br><span class="line"><span class="string">                ORDER BY 数据年月 DESC</span></span><br><span class="line"><span class="string">                LIMIT 12</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">type</span> == <span class="string">&quot;out&quot;</span>:</span><br><span class="line">        query = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                SELECT * </span></span><br><span class="line"><span class="string">                FROM trade_out </span></span><br><span class="line"><span class="string">                WHERE 贸易伙伴名称 = %s</span></span><br><span class="line"><span class="string">                  AND 商品名称 = %s</span></span><br><span class="line"><span class="string">                  AND 贸易方式名称 = %s</span></span><br><span class="line"><span class="string">                  AND 注册地名称 = %s</span></span><br><span class="line"><span class="string">                  AND 数据年月 &lt; %s</span></span><br><span class="line"><span class="string">                ORDER BY 数据年月 DESC</span></span><br><span class="line"><span class="string">                LIMIT 12</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 连接数据库并执行查询</span></span><br><span class="line">    connection = pymysql.connect(**db_config)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> connection.cursor() <span class="keyword">as</span> cursor:</span><br><span class="line">            cursor.execute(query, (friend, good, trade, register, target_date))</span><br><span class="line">            result = cursor.fetchall()</span><br><span class="line">            columns = [desc[<span class="number">0</span>] <span class="keyword">for</span> desc <span class="keyword">in</span> cursor.description]</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        connection.close()</span><br><span class="line">    <span class="keyword">return</span> result, columns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/predict_in_price&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_in_price</span>():</span><br><span class="line">    warning_msg = <span class="literal">None</span></span><br><span class="line">    result, columns = db_process(<span class="string">&quot;in&quot;</span>)</span><br><span class="line">    <span class="comment"># 转换为 DataFrame</span></span><br><span class="line">    df = pd.DataFrame(result, columns=columns)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(df) &lt; <span class="number">12</span>:</span><br><span class="line">        warning_msg = <span class="string">&quot;历史数据不足12条，预测结果准确度受影响&quot;</span></span><br><span class="line">        needed_rows = <span class="number">12</span> - <span class="built_in">len</span>(df)</span><br><span class="line">        <span class="comment"># 复制数据补齐到12条</span></span><br><span class="line">        df = pd.concat([df] * ((<span class="number">12</span> // <span class="built_in">len</span>(df)) + <span class="number">1</span>), ignore_index=<span class="literal">True</span>).head(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先提取“数据年月”字段，并做预处理</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;数据年月&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">&#x27;缺少 数据年月 字段&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 确保 &#x27;数据年月&#x27; 列是字符串类型</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">    <span class="comment"># 如果数据是 &quot;YYYY-MM-DD&quot; 格式但含 day=0</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].<span class="built_in">str</span>.replace(<span class="string">&#x27;-00&#x27;</span>, <span class="string">&#x27;-01&#x27;</span>, regex=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换为 datetime，无法解析的设为 NaT</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;数据年月&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查是否有无效日期</span></span><br><span class="line">    invalid_dates = df[df[<span class="string">&#x27;数据年月&#x27;</span>].isna()]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> invalid_dates.empty:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;</span><br><span class="line">            <span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;存在无法解析的日期，请检查以下记录:\n<span class="subst">&#123;invalid_dates.head().to_dict()&#125;</span>&#x27;</span></span><br><span class="line">        &#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取 year/month</span></span><br><span class="line">    df[<span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.year.astype(<span class="built_in">int</span>)</span><br><span class="line">    df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.month.astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查类别特征列是否存在</span></span><br><span class="line">    missing_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> df.columns]</span><br><span class="line">    <span class="keyword">if</span> missing_cols:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;缺失以下类别特征列: <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(missing_cols)&#125;</span>&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    processed_rows = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        sample_df = pd.DataFrame([row])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类别特征编码</span></span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols:</span><br><span class="line">            le = in_price_label_encoders[col]</span><br><span class="line">            sample_df[col] = le.transform(sample_df[col].astype(<span class="built_in">str</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 连续特征标准化</span></span><br><span class="line">        sample_cont = sample_df[continuous_cols].copy()</span><br><span class="line">        sample_cont_scaled = in_price_scaler_X.transform(sample_cont)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存处理后的结果</span></span><br><span class="line">        processed_rows.append(&#123;</span><br><span class="line">            <span class="string">&#x27;cat&#x27;</span>: sample_df[categorical_cols].values[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;cont&#x27;</span>: sample_cont_scaled[<span class="number">0</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造 tensor 输入</span></span><br><span class="line">    cat_array = np.array([r[<span class="string">&#x27;cat&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line">    cont_array = np.array([r[<span class="string">&#x27;cont&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line"></span><br><span class="line">    cat_tensor = torch.tensor(cat_array, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    cont_tensor = torch.tensor(cont_array, dtype=torch.float32).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型预测</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = model_in_price(cat_tensor, cont_tensor)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反变换</span></span><br><span class="line">    pred_unscaled = in_price_scaler_y.inverse_transform(output.numpy())</span><br><span class="line">    pred_original = np.expm1(pred_unscaled)  <span class="comment"># 如果用了 log1p</span></span><br><span class="line"></span><br><span class="line">    unit = <span class="string">&#x27;人民币/&#x27;</span> + df[<span class="string">&#x27;计量单位&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">&#x27;predicted_in_price&#x27;</span>: <span class="built_in">float</span>(pred_original[<span class="number">0</span>][<span class="number">0</span>]),</span><br><span class="line">        <span class="string">&#x27;unit&#x27;</span>: unit</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> warning_msg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        response[<span class="string">&#x27;warning&#x27;</span>] = warning_msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jsonify(response)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/predict_in_quantity&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_in_quantity</span>():</span><br><span class="line">    warning_msg = <span class="literal">None</span></span><br><span class="line">    result, columns = db_process(<span class="string">&quot;in&quot;</span>)</span><br><span class="line">    <span class="comment"># 转换为 DataFrame</span></span><br><span class="line">    df = pd.DataFrame(result, columns=columns)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(df) &lt; <span class="number">12</span>:</span><br><span class="line">        warning_msg = <span class="string">&quot;历史数据不足12条，预测结果准确度受影响&quot;</span></span><br><span class="line">        needed_rows = <span class="number">12</span> - <span class="built_in">len</span>(df)</span><br><span class="line">        <span class="comment"># 复制数据补齐到12条</span></span><br><span class="line">        df = pd.concat([df] * ((<span class="number">12</span> // <span class="built_in">len</span>(df)) + <span class="number">1</span>), ignore_index=<span class="literal">True</span>).head(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先提取“数据年月”字段，并做预处理</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;数据年月&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">&#x27;缺少 数据年月 字段&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 确保 &#x27;数据年月&#x27; 列是字符串类型</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">    <span class="comment"># 如果数据是 &quot;YYYY-MM-DD&quot; 格式但含 day=0</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].<span class="built_in">str</span>.replace(<span class="string">&#x27;-00&#x27;</span>, <span class="string">&#x27;-01&#x27;</span>, regex=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换为 datetime，无法解析的设为 NaT</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;数据年月&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查是否有无效日期</span></span><br><span class="line">    invalid_dates = df[df[<span class="string">&#x27;数据年月&#x27;</span>].isna()]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> invalid_dates.empty:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;</span><br><span class="line">            <span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;存在无法解析的日期，请检查以下记录:\n<span class="subst">&#123;invalid_dates.head().to_dict()&#125;</span>&#x27;</span></span><br><span class="line">        &#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取 year/month</span></span><br><span class="line">    df[<span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.year.astype(<span class="built_in">int</span>)</span><br><span class="line">    df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.month.astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查类别特征列是否存在</span></span><br><span class="line">    missing_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> df.columns]</span><br><span class="line">    <span class="keyword">if</span> missing_cols:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;缺失以下类别特征列: <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(missing_cols)&#125;</span>&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    processed_rows = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        sample_df = pd.DataFrame([row])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类别特征编码</span></span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols:</span><br><span class="line">            le = in_quantity_label_encoders[col]</span><br><span class="line">            sample_df[col] = le.transform(sample_df[col].astype(<span class="built_in">str</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 连续特征标准化</span></span><br><span class="line">        sample_cont = sample_df[continuous_cols].copy()</span><br><span class="line">        sample_cont_scaled = in_quantity_scaler_X.transform(sample_cont)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存处理后的结果</span></span><br><span class="line">        processed_rows.append(&#123;</span><br><span class="line">            <span class="string">&#x27;cat&#x27;</span>: sample_df[categorical_cols].values[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;cont&#x27;</span>: sample_cont_scaled[<span class="number">0</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造 tensor 输入</span></span><br><span class="line">    cat_array = np.array([r[<span class="string">&#x27;cat&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line">    cont_array = np.array([r[<span class="string">&#x27;cont&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line"></span><br><span class="line">    cat_tensor = torch.tensor(cat_array, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    cont_tensor = torch.tensor(cont_array, dtype=torch.float32).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型预测</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = model_in_quantity(cat_tensor, cont_tensor)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反变换</span></span><br><span class="line">    pred_unscaled = in_quantity_scaler_y.inverse_transform(output.numpy())</span><br><span class="line">    pred_original = np.expm1(pred_unscaled)  <span class="comment"># 如果用了 log1p</span></span><br><span class="line"></span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">&#x27;predicted_in_quantity&#x27;</span>: <span class="built_in">float</span>(pred_original[<span class="number">0</span>][<span class="number">0</span>]),</span><br><span class="line">        <span class="string">&#x27;unit&#x27;</span>: df[<span class="string">&#x27;计量单位&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> warning_msg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        response[<span class="string">&#x27;warning&#x27;</span>] = warning_msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jsonify(response)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/predict_out_price&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_out_price</span>():</span><br><span class="line">    warning_msg = <span class="literal">None</span></span><br><span class="line">    result, columns = db_process(<span class="string">&quot;out&quot;</span>)</span><br><span class="line">    <span class="comment"># 转换为 DataFrame</span></span><br><span class="line">    df = pd.DataFrame(result, columns=columns)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(df) &lt; <span class="number">12</span>:</span><br><span class="line">        warning_msg = <span class="string">&quot;历史数据不足12条，预测结果准确度受影响&quot;</span></span><br><span class="line">        needed_rows = <span class="number">12</span> - <span class="built_in">len</span>(df)</span><br><span class="line">        <span class="comment"># 复制数据补齐到12条</span></span><br><span class="line">        df = pd.concat([df] * ((<span class="number">12</span> // <span class="built_in">len</span>(df)) + <span class="number">1</span>), ignore_index=<span class="literal">True</span>).head(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先提取“数据年月”字段，并做预处理</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;数据年月&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">&#x27;缺少 数据年月 字段&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 确保 &#x27;数据年月&#x27; 列是字符串类型</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">    <span class="comment"># 如果数据是 &quot;YYYY-MM-DD&quot; 格式但含 day=0</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].<span class="built_in">str</span>.replace(<span class="string">&#x27;-00&#x27;</span>, <span class="string">&#x27;-01&#x27;</span>, regex=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换为 datetime，无法解析的设为 NaT</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;数据年月&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查是否有无效日期</span></span><br><span class="line">    invalid_dates = df[df[<span class="string">&#x27;数据年月&#x27;</span>].isna()]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> invalid_dates.empty:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;</span><br><span class="line">            <span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;存在无法解析的日期，请检查以下记录:\n<span class="subst">&#123;invalid_dates.head().to_dict()&#125;</span>&#x27;</span></span><br><span class="line">        &#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取 year/month</span></span><br><span class="line">    df[<span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.year.astype(<span class="built_in">int</span>)</span><br><span class="line">    df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.month.astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查类别特征列是否存在</span></span><br><span class="line">    missing_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> df.columns]</span><br><span class="line">    <span class="keyword">if</span> missing_cols:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;缺失以下类别特征列: <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(missing_cols)&#125;</span>&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    processed_rows = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        sample_df = pd.DataFrame([row])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类别特征编码</span></span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols:</span><br><span class="line">            le = out_price_label_encoders[col]</span><br><span class="line">            sample_df[col] = le.transform(sample_df[col].astype(<span class="built_in">str</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 连续特征标准化</span></span><br><span class="line">        sample_cont = sample_df[continuous_cols].copy()</span><br><span class="line">        sample_cont_scaled = out_price_scaler_X.transform(sample_cont)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存处理后的结果</span></span><br><span class="line">        processed_rows.append(&#123;</span><br><span class="line">            <span class="string">&#x27;cat&#x27;</span>: sample_df[categorical_cols].values[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;cont&#x27;</span>: sample_cont_scaled[<span class="number">0</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造 tensor 输入</span></span><br><span class="line">    cat_array = np.array([r[<span class="string">&#x27;cat&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line">    cont_array = np.array([r[<span class="string">&#x27;cont&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line"></span><br><span class="line">    cat_tensor = torch.tensor(cat_array, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    cont_tensor = torch.tensor(cont_array, dtype=torch.float32).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型预测</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = model_out_price(cat_tensor, cont_tensor)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反变换</span></span><br><span class="line">    pred_unscaled = out_price_scaler_y.inverse_transform(output.numpy())</span><br><span class="line">    pred_original = np.expm1(pred_unscaled)  <span class="comment"># 如果用了 log1p</span></span><br><span class="line"></span><br><span class="line">    unit = <span class="string">&#x27;人民币/&#x27;</span>+df[<span class="string">&#x27;计量单位&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">&#x27;predicted_out_price&#x27;</span>: <span class="built_in">float</span>(pred_original[<span class="number">0</span>][<span class="number">0</span>]),</span><br><span class="line">        <span class="string">&#x27;unit&#x27;</span>: unit</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> warning_msg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        response[<span class="string">&#x27;warning&#x27;</span>] = warning_msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jsonify(response)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/predict_out_quantity&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_out_quantity</span>():</span><br><span class="line">    warning_msg = <span class="literal">None</span></span><br><span class="line">    result, columns = db_process(<span class="string">&quot;out&quot;</span>)</span><br><span class="line">    <span class="comment"># 转换为 DataFrame</span></span><br><span class="line">    df = pd.DataFrame(result, columns=columns)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(df) &lt; <span class="number">12</span>:</span><br><span class="line">        warning_msg = <span class="string">&quot;历史数据不足12条，预测结果准确度受影响&quot;</span></span><br><span class="line">        needed_rows = <span class="number">12</span> - <span class="built_in">len</span>(df)</span><br><span class="line">        <span class="comment"># 复制数据补齐到12条</span></span><br><span class="line">        df = pd.concat([df] * ((<span class="number">12</span> // <span class="built_in">len</span>(df)) + <span class="number">1</span>), ignore_index=<span class="literal">True</span>).head(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先提取“数据年月”字段，并做预处理</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;数据年月&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">&#x27;缺少 数据年月 字段&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 确保 &#x27;数据年月&#x27; 列是字符串类型</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">    <span class="comment"># 如果数据是 &quot;YYYY-MM-DD&quot; 格式但含 day=0</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].<span class="built_in">str</span>.replace(<span class="string">&#x27;-00&#x27;</span>, <span class="string">&#x27;-01&#x27;</span>, regex=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换为 datetime，无法解析的设为 NaT</span></span><br><span class="line">    df[<span class="string">&#x27;数据年月&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;数据年月&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查是否有无效日期</span></span><br><span class="line">    invalid_dates = df[df[<span class="string">&#x27;数据年月&#x27;</span>].isna()]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> invalid_dates.empty:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;</span><br><span class="line">            <span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;存在无法解析的日期，请检查以下记录:\n<span class="subst">&#123;invalid_dates.head().to_dict()&#125;</span>&#x27;</span></span><br><span class="line">        &#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取 year/month</span></span><br><span class="line">    df[<span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.year.astype(<span class="built_in">int</span>)</span><br><span class="line">    df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;数据年月&#x27;</span>].dt.month.astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查类别特征列是否存在</span></span><br><span class="line">    missing_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> df.columns]</span><br><span class="line">    <span class="keyword">if</span> missing_cols:</span><br><span class="line">        <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;error&#x27;</span>: <span class="string">f&#x27;缺失以下类别特征列: <span class="subst">&#123;<span class="string">&quot;, &quot;</span>.join(missing_cols)&#125;</span>&#x27;</span>&#125;), <span class="number">400</span></span><br><span class="line"></span><br><span class="line">    processed_rows = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        sample_df = pd.DataFrame([row])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类别特征编码</span></span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> categorical_cols:</span><br><span class="line">            le = out_quantity_label_encoders[col]</span><br><span class="line">            sample_df[col] = le.transform(sample_df[col].astype(<span class="built_in">str</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 连续特征标准化</span></span><br><span class="line">        sample_cont = sample_df[continuous_cols].copy()</span><br><span class="line">        sample_cont_scaled = out_quantity_scaler_X.transform(sample_cont)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存处理后的结果</span></span><br><span class="line">        processed_rows.append(&#123;</span><br><span class="line">            <span class="string">&#x27;cat&#x27;</span>: sample_df[categorical_cols].values[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;cont&#x27;</span>: sample_cont_scaled[<span class="number">0</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造 tensor 输入</span></span><br><span class="line">    cat_array = np.array([r[<span class="string">&#x27;cat&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line">    cont_array = np.array([r[<span class="string">&#x27;cont&#x27;</span>] <span class="keyword">for</span> r <span class="keyword">in</span> processed_rows])</span><br><span class="line"></span><br><span class="line">    cat_tensor = torch.tensor(cat_array, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    cont_tensor = torch.tensor(cont_array, dtype=torch.float32).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型预测</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = model_out_quantity(cat_tensor, cont_tensor)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反变换</span></span><br><span class="line">    pred_unscaled = out_quantity_scaler_y.inverse_transform(output.numpy())</span><br><span class="line">    pred_original = np.expm1(pred_unscaled)  <span class="comment"># 如果用了 log1p</span></span><br><span class="line"></span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">&#x27;predicted_out_quantity&#x27;</span>: <span class="built_in">float</span>(pred_original[<span class="number">0</span>][<span class="number">0</span>]),</span><br><span class="line">        <span class="string">&#x27;unit&#x27;</span>: df[<span class="string">&#x27;计量单位&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> warning_msg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        response[<span class="string">&#x27;warning&#x27;</span>] = warning_msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jsonify(response)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(host=<span class="string">&#x27;0.0.0.0&#x27;</span>, port=<span class="number">5000</span>, debug=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2 id="代码功能逻辑"><a href="#代码功能逻辑" class="headerlink" title="代码功能逻辑"></a>代码功能逻辑</h2><h4 id="1-文件-1：进-出口贸易「数量」预测训练脚本"><a href="#1-文件-1：进-出口贸易「数量」预测训练脚本" class="headerlink" title="1. 文件 1：进/出口贸易「数量」预测训练脚本"></a>1. 文件 1：进/出口贸易「数量」预测训练脚本</h4><p><strong>核心作用</strong></p>
<ul>
<li>基于<strong>出口贸易数据</strong>，训练「LSTM+Transformer」混合模型，用于预测未来月份的贸易「数量」。</li>
</ul>
<p><strong>关键流程</strong></p>
<ol>
<li><strong>数据处理</strong>：加载出口 CSV 数据→提取年月特征→清理缺失值 / 异常值→类别特征编码（LabelEncoder）→连续特征归一化（StandardScaler）→对数变换目标变量（数量）。</li>
<li><strong>序列构建</strong>：按「商品编码」分组，生成 12 个月为窗口的时间序列数据（输入：历史 12 个月特征，输出：第 13 个月数量）。</li>
<li><strong>模型训练</strong>：定义 LSTM+Transformer 混合模型（含可学习位置编码）→使用 MSE 损失、Adam 优化器训练→早停机制防止过拟合→保存模型权重、预处理组件（scaler、label encoder）。</li>
<li><strong>评估可视化</strong>：计算 R²、MSE、MAE 指标→绘制预测 vs 真实曲线、误差分布、训练损失曲线。</li>
</ol>
<h4 id="2-文件-2：进-出口贸易「单价」预测训练脚本"><a href="#2-文件-2：进-出口贸易「单价」预测训练脚本" class="headerlink" title="2. 文件 2：进/出口贸易「单价」预测训练脚本"></a>2. 文件 2：进/出口贸易「单价」预测训练脚本</h4><p><strong>核心作用</strong></p>
<ul>
<li>基于<strong>进口贸易数据</strong>，训练「LSTM+Transformer」混合模型，用于预测未来月份的贸易「单价」。</li>
</ul>
<p><strong>关键流程</strong>（与文件 1 的差异）</p>
<ol>
<li><strong>数据差异</strong>：加载进口 CSV 数据，目标变量改为「单价」，数据保存路径指向进口模型目录。</li>
<li><strong>模型参数调整</strong>：num_heads=64、num_layers=10（更复杂模型适配单价预测），MSE 损失权重设为 0.5（降低高金额样本的影响）。</li>
<li><strong>输出产物</strong>：保存进口单价预测模型、对应的预处理组件，评估指标和可视化图表针对「单价」。</li>
</ol>
<h4 id="3-文件-3：Flask-API-部署脚本"><a href="#3-文件-3：Flask-API-部署脚本" class="headerlink" title="3. 文件 3：Flask API 部署脚本"></a>3. 文件 3：Flask API 部署脚本</h4><p><strong>核心作用</strong></p>
<ul>
<li>将前两个文件训练好的 4 个模型（进口单价 / 数量、出口单价 / 数量）封装为 HTTP 接口，通过数据库查询历史数据，提供实时预测服务。</li>
</ul>
<p><strong>关键流程</strong></p>
<ol>
<li><strong>模型加载</strong>：加载 4 个预训练模型权重、对应的 scaler 和 label encoder，初始化模型结构（与训练时一致）。</li>
<li><strong>数据库交互</strong>：提供<code>db_process</code>函数，根据请求参数（贸易伙伴、商品、时间等）查询进口 / 出口历史数据（最近 12 条）。</li>
<li><strong>接口设计</strong>：4 个 POST 接口（<code>/predict_in_price</code>/<code>in_quantity</code>/<code>out_price</code>/<code>out_quantity</code>），接收 JSON 请求。</li>
<li><strong>预测流程</strong>：<ul>
<li>数据预处理（与训练时一致：编码类别特征、归一化连续特征）。</li>
<li>处理数据不足 12 条的情况（复制补齐）。</li>
<li>模型推理，反变换预测结果（还原对数变换和标准化）。</li>
<li>返回 JSON 结果（预测值、单位、警告信息）。</li>
</ul>
</li>
</ol>
<h4 id="三者关系与整体流程"><a href="#三者关系与整体流程" class="headerlink" title="三者关系与整体流程"></a>三者关系与整体流程</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[文件1：出口数量训练] --&gt;|输出：出口数量模型+预处理组件| C[文件3：API部署]</span><br><span class="line">    B[文件2：进口单价训练] --&gt;|输出：进口单价模型+预处理组件| C</span><br><span class="line">    C --&gt;|接收请求→查询数据库→预处理→模型推理| D[前端/其他系统调用预测接口]</span><br></pre></td></tr></table></figure>

<p><svg aria-roledescription="flowchart-v2" role="graphics-document document" style="overflow: hidden; max-width: 414.48486328125px;" class="flowchart" xmlns="http://www.w3.org/2000/svg" width="100%" id="svg-mermaid-diagram-ztztias" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ev="http://www.w3.org/2001/xml-events"><g id="viewport-20251114014355014" class="svg-pan-zoom_viewport" transform="matrix(1.611639070994799,0,0,1.611639070994799,0,124.96349623835945)" style="transform: matrix(1.61164, 0, 0, 1.61164, 0, 124.963);"><g><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="5" viewBox="0 0 10 10" class="marker flowchart-v2" id="svg-mermaid-diagram-ztztias_flowchart-v2-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="4.5" viewBox="0 0 10 10" class="marker flowchart-v2" id="svg-mermaid-diagram-ztztias_flowchart-v2-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart-v2" id="svg-mermaid-diagram-ztztias_flowchart-v2-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart-v2" id="svg-mermaid-diagram-ztztias_flowchart-v2-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="svg-mermaid-diagram-ztztias_flowchart-v2-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart-v2" id="svg-mermaid-diagram-ztztias_flowchart-v2-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"></g><g class="edgePaths"><path marker-end="url(#svg-mermaid-diagram-ztztias_flowchart-v2-pointEnd)" data-points="W3sieCI6OTUuMTIxMjE1ODIwMzEyNSwieSI6NTYuMDAxODk1OTA0NTQxMDE2fSx7IngiOjk1LjEyMTIxNTgyMDMxMjUsInkiOjkwLjAwMjg0MjkwMzEzNzJ9LHsieCI6MTYwLjg0NzEyOTA4MTQ5MDI3LCJ5IjoxMjQuMDAzNzg5OTAxNzMzNH1d" data-id="L_A_C_0" data-et="edge" data-edge="true" style=";" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_A_C_0" d="M95.121,56.002L95.121,61.669C95.121,67.336,95.121,78.669,105.483,89.697C115.846,100.724,136.57,111.445,146.932,116.805L157.294,122.166"></path><path marker-end="url(#svg-mermaid-diagram-ztztias_flowchart-v2-pointEnd)" data-points="W3sieCI6MzE5LjM2MzY0NzQ2MDkzNzUsInkiOjU2LjAwMTg5NTkwNDU0MTAxNn0seyJ4IjozMTkuMzYzNjQ3NDYwOTM3NSwieSI6OTAuMDAyODQyOTAzMTM3Mn0seyJ4IjoyNTMuNjM3NzM0MTk5NzU5NzMsInkiOjEyNC4wMDM3ODk5MDE3MzM0fV0=" data-id="L_B_C_0" data-et="edge" data-edge="true" style=";" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_B_C_0" d="M319.364,56.002L319.364,61.669C319.364,67.336,319.364,78.669,309.001,89.697C298.639,100.724,277.915,111.445,267.553,116.805L257.19,122.166"></path><path marker-end="url(#svg-mermaid-diagram-ztztias_flowchart-v2-pointEnd)" data-points="W3sieCI6MjA3LjI0MjQzMTY0MDYyNSwieSI6MTcyLjAwNTY4NTgwNjI3NDR9LHsieCI6MjA3LjI0MjQzMTY0MDYyNSwieSI6MjE1LjAwNzU3OTgwMzQ2Njh9LHsieCI6MjA3LjI0MjQzMTY0MDYyNSwieSI6MjU4LjAwOTQ3MzgwMDY1OTJ9XQ==" data-id="L_C_D_0" data-et="edge" data-edge="true" style=";" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" id="L_C_D_0" d="M207.242,172.006L207.242,179.173C207.242,186.34,207.242,200.674,207.242,214.341C207.242,228.008,207.242,241.009,207.242,247.509L207.242,254.009"></path></g><g class="edgeLabels"><g transform="translate(95.1212158203125, 90.0028429031372)" class="edgeLabel"><g transform="translate(-87.10700988769531, -9.000946998596191)" data-id="L_A_C_0" class="label"><foreignObject height="18.001893997192383" width="174.21401977539062"><div class="labelBkg" xmlns="http://www.w3.org/1999/xhtml" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; background-color: rgba(245, 235, 255, 0.5); display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;"><span class="edgeLabel" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; fill: rgba(0, 0, 0, 0.8); color: rgba(0, 0, 0, 0.8); background-color: rgb(245, 235, 255); text-align: center;"><p style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding-top: var(--md-box-body-padding-top); padding-right: var(--md-box-body-padding-right); padding-bottom: var(--md-box-body-padding-bottom); padding-left: var(--md-box-body-padding-left); overflow-anchor: auto; color: var(--md-box-body-color,var(--md-box-global-text-color)); font-size: var(--md-box-body-font-size); font-weight: var(--md-box-body-font-weight); line-height: var(--md-box-body-line-height); background-color: rgb(245, 235, 255);">输出：出口数量模型+预处理组件</p></span></div></foreignObject></g></g><g transform="translate(319.3636474609375, 90.0028429031372)" class="edgeLabel"><g transform="translate(-87.10700988769531, -9.000946998596191)" data-id="L_B_C_0" class="label"><foreignObject height="18.001893997192383" width="174.21401977539062"><div class="labelBkg" xmlns="http://www.w3.org/1999/xhtml" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; background-color: rgba(245, 235, 255, 0.5); display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;"><span class="edgeLabel" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; fill: rgba(0, 0, 0, 0.8); color: rgba(0, 0, 0, 0.8); background-color: rgb(245, 235, 255); text-align: center;"><p style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding-top: var(--md-box-body-padding-top); padding-right: var(--md-box-body-padding-right); padding-bottom: var(--md-box-body-padding-bottom); padding-left: var(--md-box-body-padding-left); overflow-anchor: auto; color: var(--md-box-body-color,var(--md-box-global-text-color)); font-size: var(--md-box-body-font-size); font-weight: var(--md-box-body-font-weight); line-height: var(--md-box-body-line-height); background-color: rgb(245, 235, 255);">输出：进口单价模型+预处理组件</p></span></div></foreignObject></g></g><g transform="translate(207.242431640625, 215.0075798034668)" class="edgeLabel"><g transform="translate(-100, -18.001893997192383)" data-id="L_C_D_0" class="label"><foreignObject height="36.003787994384766" width="200"><div class="labelBkg" xmlns="http://www.w3.org/1999/xhtml" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; background-color: rgba(245, 235, 255, 0.5); display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;"><span class="edgeLabel" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; fill: rgba(0, 0, 0, 0.8); color: rgba(0, 0, 0, 0.8); background-color: rgb(245, 235, 255); text-align: center;"><p style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding-top: var(--md-box-body-padding-top); padding-right: var(--md-box-body-padding-right); padding-bottom: var(--md-box-body-padding-bottom); padding-left: var(--md-box-body-padding-left); overflow-anchor: auto; color: var(--md-box-body-color,var(--md-box-global-text-color)); font-size: var(--md-box-body-font-size); font-weight: var(--md-box-body-font-weight); line-height: var(--md-box-body-line-height); background-color: rgb(245, 235, 255);">接收请求→查询数据库→预处理→模型推理</p></span></div></foreignObject></g></g></g><g class="nodes"><g transform="translate(95.1212158203125, 32.00094795227051)" id="flowchart-A-0" class="node default"><rect height="48.00189399719238" width="174.24242401123047" y="-24.00094699859619" x="-87.12121200561523" style="" class="basic label-container"></rect><g transform="translate(-57.121212005615234, -9.000946998596191)" style="" class="label"><rect></rect><foreignObject height="18.001893997192383" width="114.24242401123047"><div xmlns="http://www.w3.org/1999/xhtml" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;"><span class="nodeLabel" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; fill: rgba(0, 0, 0, 0.8); color: rgba(0, 0, 0, 0.8);"><p style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding-top: var(--md-box-body-padding-top); padding-right: var(--md-box-body-padding-right); padding-bottom: var(--md-box-body-padding-bottom); padding-left: var(--md-box-body-padding-left); overflow-anchor: auto; color: var(--md-box-body-color,var(--md-box-global-text-color)); font-size: var(--md-box-body-font-size); font-weight: var(--md-box-body-font-weight); line-height: var(--md-box-body-line-height);">文件1：出口数量训练</p></span></div></foreignObject></g></g><g transform="translate(207.242431640625, 148.0047378540039)" id="flowchart-C-1" class="node default"><rect height="48.00189399719238" width="143.36174774169922" y="-24.00094699859619" x="-71.68087387084961" style="" class="basic label-container"></rect><g transform="translate(-41.68087387084961, -9.000946998596191)" style="" class="label"><rect></rect><foreignObject height="18.001893997192383" width="83.36174774169922"><div xmlns="http://www.w3.org/1999/xhtml" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;"><span class="nodeLabel" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; fill: rgba(0, 0, 0, 0.8); color: rgba(0, 0, 0, 0.8);"><p style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding-top: var(--md-box-body-padding-top); padding-right: var(--md-box-body-padding-right); padding-bottom: var(--md-box-body-padding-bottom); padding-left: var(--md-box-body-padding-left); overflow-anchor: auto; color: var(--md-box-body-color,var(--md-box-global-text-color)); font-size: var(--md-box-body-font-size); font-weight: var(--md-box-body-font-weight); line-height: var(--md-box-body-line-height);">文件3：API部署</p></span></div></foreignObject></g></g><g transform="translate(319.3636474609375, 32.00094795227051)" id="flowchart-B-2" class="node default"><rect height="48.00189399719238" width="174.24242401123047" y="-24.00094699859619" x="-87.12121200561523" style="" class="basic label-container"></rect><g transform="translate(-57.121212005615234, -9.000946998596191)" style="" class="label"><rect></rect><foreignObject height="18.001893997192383" width="114.24242401123047"><div xmlns="http://www.w3.org/1999/xhtml" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;"><span class="nodeLabel" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; fill: rgba(0, 0, 0, 0.8); color: rgba(0, 0, 0, 0.8);"><p style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding-top: var(--md-box-body-padding-top); padding-right: var(--md-box-body-padding-right); padding-bottom: var(--md-box-body-padding-bottom); padding-left: var(--md-box-body-padding-left); overflow-anchor: auto; color: var(--md-box-body-color,var(--md-box-global-text-color)); font-size: var(--md-box-body-font-size); font-weight: var(--md-box-body-font-weight); line-height: var(--md-box-body-line-height);">文件2：进口单价训练</p></span></div></foreignObject></g></g><g transform="translate(207.242431640625, 282.0104217529297)" id="flowchart-D-5" class="node default"><rect height="48.00189399719238" width="210.21780395507812" y="-24.00094699859619" x="-105.10890197753906" style="" class="basic label-container"></rect><g transform="translate(-75.10890197753906, -9.000946998596191)" style="" class="label"><rect></rect><foreignObject height="18.001893997192383" width="150.21780395507812"><div xmlns="http://www.w3.org/1999/xhtml" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;"><span class="nodeLabel" style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding: 0px; overflow-anchor: auto; fill: rgba(0, 0, 0, 0.8); color: rgba(0, 0, 0, 0.8);"><p style="outline: none; -webkit-font-smoothing: antialiased; box-sizing: border-box; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); border: 0px solid; margin: 0px; padding-top: var(--md-box-body-padding-top); padding-right: var(--md-box-body-padding-right); padding-bottom: var(--md-box-body-padding-bottom); padding-left: var(--md-box-body-padding-left); overflow-anchor: auto; color: var(--md-box-body-color,var(--md-box-global-text-color)); font-size: var(--md-box-body-font-size); font-weight: var(--md-box-body-font-weight); line-height: var(--md-box-body-line-height);">前端/其他系统调用预测接口</p></span></div></foreignObject></g></g></g></g></g></g></svg></p>
<h4 id="核心总结"><a href="#核心总结" class="headerlink" title="核心总结"></a>核心总结</h4><table>
<thead>
<tr>
<th>文件</th>
<th>核心目标</th>
<th>输入数据</th>
<th>输出产物</th>
</tr>
</thead>
<tbody><tr>
<td>文件 1</td>
<td>训练出口数量预测模型</td>
<td>出口贸易 CSV</td>
<td>出口数量模型、scaler、可视化图表</td>
</tr>
<tr>
<td>文件 2</td>
<td>训练进口单价预测模型</td>
<td>进口贸易 CSV</td>
<td>进口单价模型、scaler、可视化图表</td>
</tr>
<tr>
<td>文件 3</td>
<td>提供预测 API 服务</td>
<td>HTTP 请求 + 数据库数据</td>
<td>JSON 格式预测结果（单价 / 数量）</td>
</tr>
</tbody></table>
<h1 id="基于springboot框架生成后端接口"><a href="#基于springboot框架生成后端接口" class="headerlink" title="基于springboot框架生成后端接口"></a>基于springboot框架生成后端接口</h1><p>其实是基于cursor：</p>
<p>描述：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">要你基于 SpringBoot 框架开发两个接口：</span><br><span class="line">主接口：接收前端调用，按顺序执行三个 Python 脚本（先 A 进/出口数量训练、再 B 进/出口单价训练，最后 C API 部署），需支持通过代码配置进出口的 CSV 数据路径（替代手动注释切换）和模型生成路径，确保 A 自动读取进/出口 CSV、输出进/出口模型组件，B 自动读取进/出口 CSV、输出进/出口模型组件，且 A、B 的输出能被 C 正确引用。</span><br><span class="line">状态接口：向前端返回脚本执行状态（运行中、完成、失败等）。</span><br><span class="line">核心优化：修改文件 1（进/出口训练）和文件 2（进出/口训练）的代码，通过参数或配置实现进出口 CSV 导入路径、模型输出路径的自动切换 / 分别指定，无需手动注释切换路径。将完整项目代码放入新的文件目录中</span><br></pre></td></tr></table></figure>

<h2 id="项目完成情况"><a href="#项目完成情况" class="headerlink" title="项目完成情况"></a>项目完成情况</h2><h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">TradeSpringBoot/</span><br><span class="line">├── src/</span><br><span class="line">│   └── main/</span><br><span class="line">│       ├── java/com/trade/</span><br><span class="line">│       │   ├── TradeApplication.java          # 主启动类</span><br><span class="line">│       │   ├── config/</span><br><span class="line">│       │   │   └── PythonScriptProperties.java # Python 脚本配置类</span><br><span class="line">│       │   ├── controller/</span><br><span class="line">│       │   │   └── TrainingController.java     # REST 控制器</span><br><span class="line">│       │   ├── service/</span><br><span class="line">│       │   │   ├── PythonScriptService.java    # Python 脚本执行服务</span><br><span class="line">│       │   │   └── TrainingTaskService.java    # 训练任务管理服务</span><br><span class="line">│       │   ├── model/</span><br><span class="line">│       │   │   ├── ScriptExecutionResult.java  # 脚本执行结果模型</span><br><span class="line">│       │   │   └── TrainingTaskStatus.java     # 训练任务状态模型</span><br><span class="line">│       │   └── enums/</span><br><span class="line">│       │       └── ScriptStatus.java           # 脚本状态枚举</span><br><span class="line">│       └── resources/</span><br><span class="line">│           └── application.yml                 # 配置文件</span><br><span class="line">├── python-scripts/</span><br><span class="line">│   ├── Trade_Transformer_LSTM_price.py        # 单价训练脚本</span><br><span class="line">│   ├── Trade_Transformer_LSTM_quantity.py     # 数量训练脚本</span><br><span class="line">│   └── app.py                                  # Flask API 部署脚本（需从原项目复制）</span><br><span class="line">├── pom.xml                                     # Maven 配置文件</span><br><span class="line">└── README.md                                   # 项目说明文档</span><br></pre></td></tr></table></figure>

<h3 id="已创建的核心文件"><a href="#已创建的核心文件" class="headerlink" title="已创建的核心文件"></a>已创建的核心文件</h3><ol>
<li>SpringBoot 主应用</li>
</ol>
<ul>
<li><p>TradeApplication.java - 主启动类</p>
</li>
<li><p>application.yml - 配置文件</p>
</li>
</ul>
<ol start="2">
<li>配置管理</li>
</ol>
<ul>
<li>PythonScriptProperties.java - 配置属性类，支持从 YAML 读取配置</li>
</ul>
<ol start="3">
<li>REST API 控制器</li>
</ol>
<ul>
<li>TrainingController.java - 提供训练任务启动和状态查询接口</li>
</ul>
<ol start="4">
<li>服务层</li>
</ol>
<ul>
<li><p>PythonScriptService.java - Python 脚本执行服务</p>
</li>
<li><p>TrainingTaskService.java - 训练任务管理服务</p>
</li>
</ul>
<ol start="5">
<li>数据模型</li>
</ol>
<ul>
<li><p>ScriptExecutionResult.java - 脚本执行结果模型</p>
</li>
<li><p>TrainingTaskStatus.java - 训练任务状态模型</p>
</li>
<li><p>ScriptStatus.java - 状态枚举</p>
</li>
</ul>
<ol start="6">
<li>Python 脚本</li>
</ol>
<ul>
<li><p>Trade_Transformer_LSTM_price.py - 单价训练脚本（已参数化）</p>
</li>
<li><p>Trade_Transformer_LSTM_quantity.py - 数量训练脚本（已参数化）</p>
</li>
</ul>
<ol start="7">
<li>文档</li>
</ol>
<ul>
<li><p>README.md - 项目说明文档</p>
</li>
<li><p>QUICKSTART.md - 快速启动指南</p>
</li>
<li><p>PROJECT_STRUCTURE.md - 项目结构说明</p>
</li>
</ul>
<h3 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h3><ol>
<li>自动化训练流程：按顺序执行 4 个模型的训练（进口数量、进口单价、出口数量、出口单价）</li>
<li>参数化配置：通过 application.yml 配置 CSV 路径和模型输出路径，无需修改代码</li>
<li>状态跟踪：实时跟踪训练任务执行状态，支持查询进度</li>
<li>异步执行：训练任务异步执行，不阻塞主线程</li>
</ol>
<h3 id="API-接口"><a href="#API-接口" class="headerlink" title="API 接口"></a>API 接口</h3><ul>
<li><p>POST /api/training/start - 启动训练任务</p>
</li>
<li><p>GET /api/training/status/{taskId} - 查询指定任务状态</p>
</li>
<li><p>GET /api/training/status - 查询所有任务状态</p>
</li>
</ul>
<h3 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h3><p>在 application.yml 中配置：</p>
<ul>
<li><p>Python 解释器路径</p>
</li>
<li><p>CSV 数据文件路径（进口/出口）</p>
</li>
<li><p>模型输出路径（进口/出口）</p>
</li>
<li><p>脚本文件路径</p>
</li>
</ul>
<h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><ol>
<li><p>修改 application.yml 中的路径配置</p>
</li>
<li><p>运行 mvn spring-boot:run 启动服务</p>
</li>
<li><p>调用 POST /api/training/start 启动训练</p>
</li>
<li><p>通过 GET /api/training/status/{taskId} 查询状态</p>
</li>
</ol>
<p>所有代码已创建在 TradeSpringBoot 目录下，可直接使用。Python 训练脚本已支持通过命令行参数配置，无需手动修改代码。</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510132339315.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510132339315.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">zhangzhang</div><div class="post-copyright__author_desc"></div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD2%E2%80%94%E2%80%94springboot%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%20(2)/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD2%E2%80%94%E2%80%94springboot%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%20(2)/')">（项目）20251113大数据项目实施2——springboot编写脚本后台</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD2%E2%80%94%E2%80%94springboot%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%20(2)/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=（项目）20251113大数据项目实施2——springboot编写脚本后台&amp;url=http://example.com/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD2%E2%80%94%E2%80%94springboot%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%20(2)/&amp;pic=https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=d012df38-e625-0bf5-dc5f-b86079e11f31" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">zhangzhang-blog</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/RAG/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>RAG<span class="tagsPageCount">2</span></a><a class="post-meta__box__tags" href="/tags/fastgpt/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>fastgpt<span class="tagsPageCount">3</span></a><a class="post-meta__box__tags" href="/tags/Docker/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Docker<span class="tagsPageCount">3</span></a><a class="post-meta__box__tags" href="/tags/LLM/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>LLM<span class="tagsPageCount">4</span></a><a class="post-meta__box__tags" href="/tags/AI/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>AI<span class="tagsPageCount">4</span></a><a class="post-meta__box__tags" href="/tags/springboot/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>springboot<span class="tagsPageCount">2</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=10811431-7127-a7b9-85e0-8561d6baf3a6" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD1%E2%80%94%E2%80%94%E6%B5%8B%E8%AF%95%20FastGPT%20%E4%B8%AD%20RAG%20%E6%9F%A5%E8%AF%A2%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=8151380d-6000-8bef-75e5-1063d0934fce" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">（项目）20251113大数据项目实施1——测试 FastGPT 中 RAG 查询的准确率</div></div></a></div><div class="next-post pull-right"><a href="/2025/11/17/%EF%BC%88LeetCodeHot100%EF%BC%892.%20%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0%E2%80%94%E2%80%94add-two-numbers/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=20f4fc94-dbfa-f7d3-63c7-df10b84c392d" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">（LeetCodeHot100）2. 两数相加——add-two-numbers</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2025/11/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251113%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD1%E2%80%94%E2%80%94%E6%B5%8B%E8%AF%95%20FastGPT%20%E4%B8%AD%20RAG%20%E6%9F%A5%E8%AF%A2%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87/" title="（项目）20251113大数据项目实施1——测试 FastGPT 中 RAG 查询的准确率"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=8151380d-6000-8bef-75e5-1063d0934fce" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-11-17</div><div class="title">（项目）20251113大数据项目实施1——测试 FastGPT 中 RAG 查询的准确率</div></div></a></div><div><a href="/2025/10/17/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%89%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E5%85%A8%E8%A7%A3%E6%9E%90%EF%BC%9A%E4%BB%8E%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E5%88%B0%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8C%87%E5%8D%97/" title="智能问答系统全解析：从核心架构到落地实践的技术指南"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=d1183061-bd12-14e3-153d-d598279830ed" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-10-17</div><div class="title">智能问答系统全解析：从核心架构到落地实践的技术指南</div></div></a></div><div><a href="/2025/11/19/%EF%BC%88%E9%A1%B9%E7%9B%AE%EF%BC%8920251119%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD3%E2%80%94%E2%80%94%E8%B0%83%E8%AF%95%E5%90%8E%E5%8F%B0&&%E6%B5%8B%E8%AF%95API/" title="（项目）20251119大数据项目实施3——调试后台&amp;&amp;测试API"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=130836ca-8e11-12b4-4249-8d6e910444ea" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-11-19</div><div class="title">（项目）20251119大数据项目实施3——调试后台&amp;&amp;测试API</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510132339315.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description"></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510132339315.jpg" style="width: 100%; height: auto; display: block; border-radius: 8px;"></div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%B0%81%E8%A3%85%E6%A8%A1%E5%9E%8B%E9%87%8D%E8%AE%AD%E7%BB%83-%E9%87%8D%E9%83%A8%E7%BD%B2%E6%8E%A5%E5%8F%A3%EF%BC%8C%E5%AE%9E%E7%8E%B0%E7%8A%B6%E6%80%81%E7%9B%91%E6%8E%A7%E5%B9%B6%E5%AF%B9%E6%8E%A5%E5%89%8D%E7%AB%AF%E4%B8%8E-FastGPT"><span class="toc-number">1.</span> <span class="toc-text">二、封装模型重训练 + 重部署接口，实现状态监控并对接前端与 FastGPT</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E4%B8%89%E6%AE%B5%E5%8A%9F%E8%83%BD%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BB%A3%E7%A0%81%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">现有三段功能不同的代码：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Trade-Transformer-LSTM-price-py"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">1.Trade_Transformer_LSTM_price.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Trade-Transformer-LSTM-quantity-py"><span class="toc-number">1.1.0.2.</span> <span class="toc-text">2.Trade_Transformer_LSTM_quantity.py</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-app-py-Trade-FlaskApp-Transformer-py"><span class="toc-number">1.1.0.3.</span> <span class="toc-text">3.app.py&#x2F;Trade_FlaskApp_Transformer.py</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%8A%9F%E8%83%BD%E9%80%BB%E8%BE%91"><span class="toc-number">1.2.</span> <span class="toc-text">代码功能逻辑</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%96%87%E4%BB%B6-1%EF%BC%9A%E8%BF%9B-%E5%87%BA%E5%8F%A3%E8%B4%B8%E6%98%93%E3%80%8C%E6%95%B0%E9%87%8F%E3%80%8D%E9%A2%84%E6%B5%8B%E8%AE%AD%E7%BB%83%E8%84%9A%E6%9C%AC"><span class="toc-number">1.2.0.1.</span> <span class="toc-text">1. 文件 1：进&#x2F;出口贸易「数量」预测训练脚本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%96%87%E4%BB%B6-2%EF%BC%9A%E8%BF%9B-%E5%87%BA%E5%8F%A3%E8%B4%B8%E6%98%93%E3%80%8C%E5%8D%95%E4%BB%B7%E3%80%8D%E9%A2%84%E6%B5%8B%E8%AE%AD%E7%BB%83%E8%84%9A%E6%9C%AC"><span class="toc-number">1.2.0.2.</span> <span class="toc-text">2. 文件 2：进&#x2F;出口贸易「单价」预测训练脚本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%96%87%E4%BB%B6-3%EF%BC%9AFlask-API-%E9%83%A8%E7%BD%B2%E8%84%9A%E6%9C%AC"><span class="toc-number">1.2.0.3.</span> <span class="toc-text">3. 文件 3：Flask API 部署脚本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB%E4%B8%8E%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.0.4.</span> <span class="toc-text">三者关系与整体流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93"><span class="toc-number">1.2.0.5.</span> <span class="toc-text">核心总结</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8Espringboot%E6%A1%86%E6%9E%B6%E7%94%9F%E6%88%90%E5%90%8E%E7%AB%AF%E6%8E%A5%E5%8F%A3"><span class="toc-number">2.</span> <span class="toc-text">基于springboot框架生成后端接口</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E5%AE%8C%E6%88%90%E6%83%85%E5%86%B5"><span class="toc-number">2.1.</span> <span class="toc-text">项目完成情况</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84"><span class="toc-number">2.1.1.</span> <span class="toc-text">项目结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%B2%E5%88%9B%E5%BB%BA%E7%9A%84%E6%A0%B8%E5%BF%83%E6%96%87%E4%BB%B6"><span class="toc-number">2.1.2.</span> <span class="toc-text">已创建的核心文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD"><span class="toc-number">2.1.3.</span> <span class="toc-text">核心功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#API-%E6%8E%A5%E5%8F%A3"><span class="toc-number">2.1.4.</span> <span class="toc-text">API 接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E"><span class="toc-number">2.1.5.</span> <span class="toc-text">配置说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4"><span class="toc-number">2.1.6.</span> <span class="toc-text">使用步骤</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/12/24/%EF%BC%88LeetCodeHot100%EF%BC%89200.%20%E5%B2%9B%E5%B1%BF%E6%95%B0%E9%87%8F%E2%80%94%E2%80%94number-of-islands/" title="（LeetCodeHot100）200. 岛屿数量——number-of-islands"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=f6741fc9-528f-6f04-fd87-a99f39fb9714" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="（LeetCodeHot100）200. 岛屿数量——number-of-islands"/></a><div class="content"><a class="title" href="/2025/12/24/%EF%BC%88LeetCodeHot100%EF%BC%89200.%20%E5%B2%9B%E5%B1%BF%E6%95%B0%E9%87%8F%E2%80%94%E2%80%94number-of-islands/" title="（LeetCodeHot100）200. 岛屿数量——number-of-islands">（LeetCodeHot100）200. 岛屿数量——number-of-islands</a><time datetime="2025-12-24T02:51:00.000Z" title="发表于 2025-12-24 10:51:00">2025-12-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/23/%EF%BC%88LeetCodeHot100%EF%BC%89198.%20%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D%E2%80%94%E2%80%94house-robber/" title="（LeetCodeHot100）198. 打家劫舍——house-robber"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=10811431-7127-a7b9-85e0-8561d6baf3a6" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="（LeetCodeHot100）198. 打家劫舍——house-robber"/></a><div class="content"><a class="title" href="/2025/12/23/%EF%BC%88LeetCodeHot100%EF%BC%89198.%20%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D%E2%80%94%E2%80%94house-robber/" title="（LeetCodeHot100）198. 打家劫舍——house-robber">（LeetCodeHot100）198. 打家劫舍——house-robber</a><time datetime="2025-12-23T04:23:00.000Z" title="发表于 2025-12-23 12:23:00">2025-12-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/23/%EF%BC%88LeetCodeHot100%EF%BC%89155.%20%E6%9C%80%E5%B0%8F%E6%A0%88%E2%80%94%E2%80%94min-stack/" title="（LeetCodeHot100）155. 最小栈——min-stack"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=865b27fd-f3cb-bb56-daaf-c6fb18706ea8" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="（LeetCodeHot100）155. 最小栈——min-stack"/></a><div class="content"><a class="title" href="/2025/12/23/%EF%BC%88LeetCodeHot100%EF%BC%89155.%20%E6%9C%80%E5%B0%8F%E6%A0%88%E2%80%94%E2%80%94min-stack/" title="（LeetCodeHot100）155. 最小栈——min-stack">（LeetCodeHot100）155. 最小栈——min-stack</a><time datetime="2025-12-23T02:52:00.000Z" title="发表于 2025-12-23 10:52:00">2025-12-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/22/%EF%BC%88LeetCodeHot100%EF%BC%89152.%20%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E5%AD%90%E6%95%B0%E7%BB%84%E2%80%94%E2%80%94maximum-product-subarray/" title="（LeetCodeHot100）152. 乘积最大子数组——maximum-product-subarray"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=6c700eb2-89dc-402e-5061-6f23fc4b4ea6" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="（LeetCodeHot100）152. 乘积最大子数组——maximum-product-subarray"/></a><div class="content"><a class="title" href="/2025/12/22/%EF%BC%88LeetCodeHot100%EF%BC%89152.%20%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E5%AD%90%E6%95%B0%E7%BB%84%E2%80%94%E2%80%94maximum-product-subarray/" title="（LeetCodeHot100）152. 乘积最大子数组——maximum-product-subarray">（LeetCodeHot100）152. 乘积最大子数组——maximum-product-subarray</a><time datetime="2025-12-22T09:04:00.000Z" title="发表于 2025-12-22 17:04:00">2025-12-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/22/%EF%BC%88LeetCodeHot100%EF%BC%89148.%20%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E2%80%94%E2%80%94sort-list/" title="（LeetCodeHot100）148. 排序链表——sort-list"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://zhangzhanglaila.oss-cn-beijing.aliyuncs.com/202510152221253.JPG?_r_=9be462fa-38a2-feaf-6b4a-efd52b46ee51" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="（LeetCodeHot100）148. 排序链表——sort-list"/></a><div class="content"><a class="title" href="/2025/12/22/%EF%BC%88LeetCodeHot100%EF%BC%89148.%20%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E2%80%94%E2%80%94sort-list/" title="（LeetCodeHot100）148. 排序链表——sort-list">（LeetCodeHot100）148. 排序链表——sort-list</a><time datetime="2025-12-22T08:04:00.000Z" title="发表于 2025-12-22 16:04:00">2025-12-22</time></div></div></div></div><div class="card-widget card-map"><div class="card-content"><div class="item-headline"><i class="fa fa-globe-asia" aria-hidden="true"></i><span>访客地图</span></div><script id="clstr_globe" type="text/javascript" defer="defer" src="//clustrmaps.com/globe.js?d=NrKXiqwOJfxSliMr6I1UmdORp6XDbtPAqaHcIkDWbOc"></script></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2020 - 2025 By <a class="footer-bar-link" href="/" title="zhangzhang" target="_blank">zhangzhang</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">182</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">7</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/BFS/" style="font-size: 0.88rem;">BFS<sup>6</sup></a><a href="/tags/Boyer-Moore/" style="font-size: 0.88rem;">Boyer-Moore<sup>1</sup></a><a href="/tags/DFS/" style="font-size: 0.88rem;">DFS<sup>12</sup></a><a href="/tags/DP/" style="font-size: 0.88rem;">DP<sup>11</sup></a><a href="/tags/Hash/" style="font-size: 0.88rem;">Hash<sup>14</sup></a><a href="/tags/Java/" style="font-size: 0.88rem;">Java<sup>62</sup></a><a href="/tags/Kadane-%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">Kadane 算法<sup>1</sup></a><a href="/tags/LeetCode/" style="font-size: 0.88rem;">LeetCode<sup>59</sup></a><a href="/tags/MySQL/" style="font-size: 0.88rem;">MySQL<sup>1</sup></a><a href="/tags/PTA/" style="font-size: 0.88rem;">PTA<sup>93</sup></a><a href="/tags/c/" style="font-size: 0.88rem;">c<sup>29</sup></a><a href="/tags/c/" style="font-size: 0.88rem;">c++<sup>75</sup></a><a href="/tags/git/" style="font-size: 0.88rem;">git<sup>1</sup></a><a href="/tags/vim/" style="font-size: 0.88rem;">vim<sup>1</sup></a><a href="/tags/%E4%B8%89%E6%8C%87%E9%92%88/" style="font-size: 0.88rem;">三指针<sup>5</sup></a><a href="/tags/%E4%B8%B2/" style="font-size: 0.88rem;">串<sup>2</sup></a><a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 0.88rem;">二叉树<sup>6</sup></a><a href="/tags/%E4%BD%9C%E4%B8%9A/" style="font-size: 0.88rem;">作业<sup>73</sup></a><a href="/tags/%E5%85%B1%E4%BA%AB%E6%A0%88/" style="font-size: 0.88rem;">共享栈<sup>1</sup></a><a href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/" style="font-size: 0.88rem;">双指针<sup>20</sup></a><a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 0.88rem;">回溯<sup>6</sup></a><a href="/tags/%E5%9B%BE/" style="font-size: 0.88rem;">图<sup>8</sup></a><a href="/tags/%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/" style="font-size: 0.88rem;">图床搭建<sup>1</sup></a><a href="/tags/%E5%A4%8D%E4%B9%A0/" style="font-size: 0.88rem;">复习<sup>6</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 0.88rem;">工具<sup>9</sup></a><a href="/tags/%E5%BD%92%E5%B9%B6/" style="font-size: 0.88rem;">归并<sup>1</sup></a><a href="/tags/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88/" style="font-size: 0.88rem;">快慢指针<sup>7</sup></a><a href="/tags/%E6%8F%92%E4%BB%B6/" style="font-size: 0.88rem;">插件<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 0.88rem;">数据结构<sup>99</sup></a><a href="/tags/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/" style="font-size: 0.88rem;">栈和队列<sup>25</sup></a><a href="/tags/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 0.88rem;">树和二叉树<sup>18</sup></a><a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 0.88rem;">笔记<sup>4</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">算法<sup>161</sup></a><a href="/tags/%E7%BA%BF%E6%80%A7%E8%A1%A8/" style="font-size: 0.88rem;">线性表<sup>1</sup></a><a href="/tags/%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/" style="font-size: 0.88rem;">缓存问题<sup>1</sup></a><a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 0.88rem;">贪心<sup>2</sup></a><a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 0.88rem;">递归<sup>3</sup></a><a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 0.88rem;">链表<sup>36</sup></a><a href="/tags/%E9%98%BF%E9%87%8C%E4%BA%91/" style="font-size: 0.88rem;">阿里云<sup>1</sup></a><a href="/tags/%E9%A1%BA%E5%BA%8F%E8%A1%A8/" style="font-size: 0.88rem;">顺序表<sup>19</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("04/01/2021 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2020 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 zhangzhang 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script><script async data-pjax src="/js/txmap.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="true"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>